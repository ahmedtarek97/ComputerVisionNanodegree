{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "**Answer:** I used the recommended and pretrained resnet 50 as the CNN encoder then an embeding layer with changes from vocab_size to embed_size and a linear fully connected layer with dimensions (hidden_size, vocab_size) , and for the are RNN decoder I used the same architecture as the recommended paper Show and Tell: A Neural Image Caption Generator \n",
    "\n",
    "The hyperparameters: \n",
    "\n",
    "**batch_size =32** as 32 will help to spped the computations also i didn't wan't to choose a large number to avoid memory errors\n",
    "\n",
    "**vocab_threshold = 4** to increase the number of vocabulary avilable but we I also load the vocabulary list so this number I think has no effect in this case\n",
    "\n",
    "**embed_size and hidden_size = 512**: I got these to values from the paper (Show and Tell)\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "**Answer:** \n",
    " I did not change the given transform .RandomCrop and RandomHorizontalFlip is enough for image agumentation.The input of the CNN-encoder is an image of size (224 x 224 x 3), so this is the final size of the image we are aiming for.The normalize value is same that of Resnet spacified. so i didn't change it\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "**Answer:**\n",
    "The CNN-encoder is taken from a pre-trained model so that we do not need to retrain the model from scratch. but we only need to train the embed layer from the encoder an the all the parameters of the decoder\n",
    "**batch_size =32** as 32 will help to spped the computations also i didn't wan't to choose a large number to avoid memory errors\n",
    "\n",
    "**num_epochs= 3** as it is recommended in the papers given in this notebook also because of the time constrains as i train i  the Udacity workspace \n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "**Answer:** \n",
    "the paper Show, Attend and Tell it was shown that the Adam (Adaptive Momentum) algorithm performed the best results.\n",
    "also as it is an adaptive optimizer is better since it keeps track of the previous gradient and avoids local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.2.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk) (1.11.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 374/414113 [00:00<01:50, 3738.08it/s]\u001b[A\n",
      "  0%|          | 732/414113 [00:00<01:52, 3687.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=1.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "  0%|          | 1157/414113 [00:00<01:47, 3838.20it/s]\u001b[A\n",
      "  0%|          | 1562/414113 [00:00<01:45, 3896.91it/s]\u001b[A\n",
      "  0%|          | 1973/414113 [00:00<01:44, 3957.98it/s]\u001b[A\n",
      "  1%|          | 2396/414113 [00:00<01:42, 4034.00it/s]\u001b[A\n",
      "  1%|          | 2817/414113 [00:00<01:40, 4084.22it/s]\u001b[A\n",
      "  1%|          | 3240/414113 [00:00<01:39, 4124.15it/s]\u001b[A\n",
      "  1%|          | 3672/414113 [00:00<01:38, 4178.89it/s]\u001b[A\n",
      "  1%|          | 4108/414113 [00:01<01:36, 4230.83it/s]\u001b[A\n",
      "  1%|          | 4541/414113 [00:01<01:36, 4259.35it/s]\u001b[A\n",
      "  1%|          | 4982/414113 [00:01<01:35, 4301.26it/s]\u001b[A\n",
      "  1%|▏         | 5422/414113 [00:01<01:34, 4327.57it/s]\u001b[A\n",
      "  1%|▏         | 5863/414113 [00:01<01:33, 4351.18it/s]\u001b[A\n",
      "  2%|▏         | 6296/414113 [00:01<01:34, 4304.47it/s]\u001b[A\n",
      "  2%|▏         | 6736/414113 [00:01<01:34, 4332.61it/s]\u001b[A\n",
      "  2%|▏         | 7169/414113 [00:01<01:38, 4121.45it/s]\u001b[A\n",
      "  2%|▏         | 7595/414113 [00:01<01:37, 4159.65it/s]\u001b[A\n",
      "  2%|▏         | 8020/414113 [00:01<01:37, 4183.95it/s]\u001b[A\n",
      "  2%|▏         | 8457/414113 [00:02<01:35, 4237.26it/s]\u001b[A\n",
      "  2%|▏         | 8882/414113 [00:02<01:36, 4219.85it/s]\u001b[A\n",
      "  2%|▏         | 9310/414113 [00:02<01:35, 4235.55it/s]\u001b[A\n",
      "  2%|▏         | 9734/414113 [00:02<01:39, 4062.30it/s]\u001b[A\n",
      "  2%|▏         | 10159/414113 [00:02<01:38, 4116.70it/s]\u001b[A\n",
      "  3%|▎         | 10573/414113 [00:02<01:38, 4105.88it/s]\u001b[A\n",
      "  3%|▎         | 10992/414113 [00:02<01:37, 4129.47it/s]\u001b[A\n",
      "  3%|▎         | 11408/414113 [00:02<01:37, 4137.12it/s]\u001b[A\n",
      "  3%|▎         | 11823/414113 [00:02<01:37, 4134.49it/s]\u001b[A\n",
      "  3%|▎         | 12248/414113 [00:02<01:36, 4168.34it/s]\u001b[A\n",
      "  3%|▎         | 12674/414113 [00:03<01:35, 4195.16it/s]\u001b[A\n",
      "  3%|▎         | 13106/414113 [00:03<01:34, 4229.65it/s]\u001b[A\n",
      "  3%|▎         | 13546/414113 [00:03<01:33, 4278.94it/s]\u001b[A\n",
      "  3%|▎         | 13975/414113 [00:03<01:33, 4270.30it/s]\u001b[A\n",
      "  3%|▎         | 14403/414113 [00:03<01:34, 4227.82it/s]\u001b[A\n",
      "  4%|▎         | 14827/414113 [00:03<01:34, 4213.96it/s]\u001b[A\n",
      "  4%|▎         | 15253/414113 [00:03<01:34, 4226.02it/s]\u001b[A\n",
      "  4%|▍         | 15681/414113 [00:03<01:33, 4240.15it/s]\u001b[A\n",
      "  4%|▍         | 16106/414113 [00:03<01:34, 4229.00it/s]\u001b[A\n",
      "  4%|▍         | 16534/414113 [00:03<01:33, 4242.37it/s]\u001b[A\n",
      "  4%|▍         | 16959/414113 [00:04<01:34, 4214.20it/s]\u001b[A\n",
      "  4%|▍         | 17383/414113 [00:04<01:33, 4221.78it/s]\u001b[A\n",
      "  4%|▍         | 17824/414113 [00:04<01:32, 4273.54it/s]\u001b[A\n",
      "  4%|▍         | 18256/414113 [00:04<01:32, 4282.18it/s]\u001b[A\n",
      "  5%|▍         | 18685/414113 [00:04<01:32, 4271.61it/s]\u001b[A\n",
      "  5%|▍         | 19113/414113 [00:04<01:32, 4255.34it/s]\u001b[A\n",
      "  5%|▍         | 19547/414113 [00:04<01:32, 4278.52it/s]\u001b[A\n",
      "  5%|▍         | 19975/414113 [00:04<01:32, 4262.52it/s]\u001b[A\n",
      "  5%|▍         | 20402/414113 [00:04<01:32, 4246.40it/s]\u001b[A\n",
      "  5%|▌         | 20827/414113 [00:04<01:33, 4185.28it/s]\u001b[A\n",
      "  5%|▌         | 21246/414113 [00:05<01:34, 4177.07it/s]\u001b[A\n",
      "  5%|▌         | 21680/414113 [00:05<01:32, 4223.80it/s]\u001b[A\n",
      "  5%|▌         | 22121/414113 [00:05<01:31, 4276.77it/s]\u001b[A\n",
      "  5%|▌         | 22555/414113 [00:05<01:31, 4294.15it/s]\u001b[A\n",
      "  6%|▌         | 23004/414113 [00:05<01:29, 4350.24it/s]\u001b[A\n",
      "  6%|▌         | 23440/414113 [00:05<01:31, 4280.52it/s]\u001b[A\n",
      "  6%|▌         | 23872/414113 [00:05<01:30, 4291.81it/s]\u001b[A\n",
      "  6%|▌         | 24304/414113 [00:05<01:30, 4297.56it/s]\u001b[A\n",
      "  6%|▌         | 24735/414113 [00:05<01:31, 4243.76it/s]\u001b[A\n",
      "  6%|▌         | 25160/414113 [00:05<01:31, 4244.03it/s]\u001b[A\n",
      "  6%|▌         | 25585/414113 [00:06<01:31, 4239.97it/s]\u001b[A\n",
      "  6%|▋         | 26010/414113 [00:06<01:31, 4231.60it/s]\u001b[A\n",
      "  6%|▋         | 26441/414113 [00:06<01:31, 4253.52it/s]\u001b[A\n",
      "  6%|▋         | 26867/414113 [00:06<01:31, 4248.69it/s]\u001b[A\n",
      "  7%|▋         | 27292/414113 [00:06<01:31, 4236.30it/s]\u001b[A\n",
      "  7%|▋         | 27716/414113 [00:06<01:31, 4222.81it/s]\u001b[A\n",
      "  7%|▋         | 28150/414113 [00:06<01:30, 4253.87it/s]\u001b[A\n",
      "  7%|▋         | 28576/414113 [00:06<01:30, 4244.54it/s]\u001b[A\n",
      "  7%|▋         | 29001/414113 [00:06<01:31, 4222.63it/s]\u001b[A\n",
      "  7%|▋         | 29431/414113 [00:06<01:30, 4244.24it/s]\u001b[A\n",
      "  7%|▋         | 29856/414113 [00:07<01:30, 4230.37it/s]\u001b[A\n",
      "  7%|▋         | 30295/414113 [00:07<01:29, 4276.08it/s]\u001b[A\n",
      "  7%|▋         | 30730/414113 [00:07<01:29, 4297.65it/s]\u001b[A\n",
      "  8%|▊         | 31183/414113 [00:07<01:27, 4362.56it/s]\u001b[A\n",
      "  8%|▊         | 31620/414113 [00:07<01:28, 4343.82it/s]\u001b[A\n",
      "  8%|▊         | 32055/414113 [00:07<01:28, 4309.33it/s]\u001b[A\n",
      "  8%|▊         | 32487/414113 [00:07<01:28, 4303.85it/s]\u001b[A\n",
      "  8%|▊         | 32918/414113 [00:07<01:29, 4282.31it/s]\u001b[A\n",
      "  8%|▊         | 33347/414113 [00:07<01:29, 4266.70it/s]\u001b[A\n",
      "  8%|▊         | 33774/414113 [00:07<01:29, 4261.65it/s]\u001b[A\n",
      "  8%|▊         | 34212/414113 [00:08<01:28, 4294.78it/s]\u001b[A\n",
      "  8%|▊         | 34642/414113 [00:08<01:28, 4270.40it/s]\u001b[A\n",
      "  8%|▊         | 35070/414113 [00:08<01:29, 4231.80it/s]\u001b[A\n",
      "  9%|▊         | 35494/414113 [00:08<01:30, 4195.76it/s]\u001b[A\n",
      "  9%|▊         | 35914/414113 [00:08<01:30, 4172.23it/s]\u001b[A\n",
      "  9%|▉         | 36339/414113 [00:08<01:30, 4192.31it/s]\u001b[A\n",
      "  9%|▉         | 36760/414113 [00:08<01:29, 4196.65it/s]\u001b[A\n",
      "  9%|▉         | 37182/414113 [00:08<01:29, 4202.34it/s]\u001b[A\n",
      "  9%|▉         | 37620/414113 [00:08<01:28, 4251.91it/s]\u001b[A\n",
      "  9%|▉         | 38052/414113 [00:09<01:28, 4271.71it/s]\u001b[A\n",
      "  9%|▉         | 38487/414113 [00:09<01:27, 4292.03it/s]\u001b[A\n",
      "  9%|▉         | 38923/414113 [00:09<01:27, 4310.34it/s]\u001b[A\n",
      " 10%|▉         | 39355/414113 [00:09<01:26, 4308.03it/s]\u001b[A\n",
      " 10%|▉         | 39786/414113 [00:09<01:26, 4303.51it/s]\u001b[A\n",
      " 10%|▉         | 40217/414113 [00:09<01:30, 4132.66it/s]\u001b[A\n",
      " 10%|▉         | 40646/414113 [00:09<01:29, 4178.50it/s]\u001b[A\n",
      " 10%|▉         | 41066/414113 [00:09<01:29, 4146.61it/s]\u001b[A\n",
      " 10%|█         | 41493/414113 [00:09<01:29, 4180.36it/s]\u001b[A\n",
      " 10%|█         | 41912/414113 [00:09<01:29, 4181.05it/s]\u001b[A\n",
      " 10%|█         | 42340/414113 [00:10<01:28, 4208.83it/s]\u001b[A\n",
      " 10%|█         | 42762/414113 [00:10<01:28, 4203.68it/s]\u001b[A\n",
      " 10%|█         | 43183/414113 [00:10<01:29, 4134.06it/s]\u001b[A\n",
      " 11%|█         | 43599/414113 [00:10<01:29, 4141.48it/s]\u001b[A\n",
      " 11%|█         | 44022/414113 [00:10<01:28, 4165.65it/s]\u001b[A\n",
      " 11%|█         | 44449/414113 [00:10<01:28, 4195.77it/s]\u001b[A\n",
      " 11%|█         | 44869/414113 [00:10<01:28, 4185.70it/s]\u001b[A\n",
      " 11%|█         | 45301/414113 [00:10<01:27, 4223.66it/s]\u001b[A\n",
      " 11%|█         | 45724/414113 [00:10<01:27, 4219.56it/s]\u001b[A\n",
      " 11%|█         | 46151/414113 [00:10<01:26, 4232.48it/s]\u001b[A\n",
      " 11%|█         | 46583/414113 [00:11<01:26, 4255.92it/s]\u001b[A\n",
      " 11%|█▏        | 47023/414113 [00:11<01:25, 4297.81it/s]\u001b[A\n",
      " 11%|█▏        | 47453/414113 [00:11<01:25, 4273.22it/s]\u001b[A\n",
      " 12%|█▏        | 47881/414113 [00:11<01:31, 4021.45it/s]\u001b[A\n",
      " 12%|█▏        | 48319/414113 [00:11<01:28, 4119.74it/s]\u001b[A\n",
      " 12%|█▏        | 48742/414113 [00:11<01:28, 4151.34it/s]\u001b[A\n",
      " 12%|█▏        | 49166/414113 [00:11<01:27, 4176.52it/s]\u001b[A\n",
      " 12%|█▏        | 49590/414113 [00:11<01:26, 4193.06it/s]\u001b[A\n",
      " 12%|█▏        | 50021/414113 [00:11<01:26, 4225.28it/s]\u001b[A\n",
      " 12%|█▏        | 50445/414113 [00:11<01:26, 4197.06it/s]\u001b[A\n",
      " 12%|█▏        | 50874/414113 [00:12<01:25, 4224.23it/s]\u001b[A\n",
      " 12%|█▏        | 51302/414113 [00:12<01:25, 4237.85it/s]\u001b[A\n",
      " 12%|█▏        | 51727/414113 [00:12<01:25, 4225.91it/s]\u001b[A\n",
      " 13%|█▎        | 52152/414113 [00:12<01:25, 4230.44it/s]\u001b[A\n",
      " 13%|█▎        | 52588/414113 [00:12<01:24, 4266.93it/s]\u001b[A\n",
      " 13%|█▎        | 53016/414113 [00:12<01:24, 4268.74it/s]\u001b[A\n",
      " 13%|█▎        | 53444/414113 [00:12<01:24, 4270.67it/s]\u001b[A\n",
      " 13%|█▎        | 53875/414113 [00:12<01:24, 4280.38it/s]\u001b[A\n",
      " 13%|█▎        | 54304/414113 [00:12<01:24, 4275.76it/s]\u001b[A\n",
      " 13%|█▎        | 54753/414113 [00:12<01:22, 4335.70it/s]\u001b[A\n",
      " 13%|█▎        | 55209/414113 [00:13<01:21, 4398.33it/s]\u001b[A\n",
      " 13%|█▎        | 55650/414113 [00:13<01:24, 4257.48it/s]\u001b[A\n",
      " 14%|█▎        | 56088/414113 [00:13<01:23, 4292.26it/s]\u001b[A\n",
      " 14%|█▎        | 56519/414113 [00:13<01:23, 4280.14it/s]\u001b[A\n",
      " 14%|█▍        | 56954/414113 [00:13<01:23, 4297.80it/s]\u001b[A\n",
      " 14%|█▍        | 57385/414113 [00:13<01:23, 4276.14it/s]\u001b[A\n",
      " 14%|█▍        | 57813/414113 [00:13<01:24, 4239.85it/s]\u001b[A\n",
      " 14%|█▍        | 58242/414113 [00:13<01:23, 4252.92it/s]\u001b[A\n",
      " 14%|█▍        | 58668/414113 [00:13<01:23, 4246.76it/s]\u001b[A\n",
      " 14%|█▍        | 59102/414113 [00:13<01:23, 4274.02it/s]\u001b[A\n",
      " 14%|█▍        | 59543/414113 [00:14<01:22, 4313.79it/s]\u001b[A\n",
      " 14%|█▍        | 59975/414113 [00:14<01:22, 4298.34it/s]\u001b[A\n",
      " 15%|█▍        | 60405/414113 [00:14<01:22, 4274.35it/s]\u001b[A\n",
      " 15%|█▍        | 60833/414113 [00:14<01:23, 4234.93it/s]\u001b[A\n",
      " 15%|█▍        | 61262/414113 [00:14<01:23, 4248.29it/s]\u001b[A\n",
      " 15%|█▍        | 61687/414113 [00:14<01:23, 4216.10it/s]\u001b[A\n",
      " 15%|█▍        | 62109/414113 [00:14<01:24, 4156.02it/s]\u001b[A\n",
      " 15%|█▌        | 62531/414113 [00:14<01:24, 4172.13it/s]\u001b[A\n",
      " 15%|█▌        | 62949/414113 [00:14<01:24, 4165.33it/s]\u001b[A\n",
      " 15%|█▌        | 63375/414113 [00:14<01:23, 4191.56it/s]\u001b[A\n",
      " 15%|█▌        | 63808/414113 [00:15<01:22, 4231.48it/s]\u001b[A\n",
      " 16%|█▌        | 64244/414113 [00:15<01:22, 4266.33it/s]\u001b[A\n",
      " 16%|█▌        | 64671/414113 [00:15<01:21, 4265.26it/s]\u001b[A\n",
      " 16%|█▌        | 65119/414113 [00:15<01:20, 4324.94it/s]\u001b[A\n",
      " 16%|█▌        | 65552/414113 [00:15<01:20, 4318.89it/s]\u001b[A\n",
      " 16%|█▌        | 65985/414113 [00:15<01:20, 4308.28it/s]\u001b[A\n",
      " 16%|█▌        | 66416/414113 [00:15<01:21, 4280.08it/s]\u001b[A\n",
      " 16%|█▌        | 66847/414113 [00:15<01:20, 4288.28it/s]\u001b[A\n",
      " 16%|█▌        | 67276/414113 [00:15<01:21, 4256.07it/s]\u001b[A\n",
      " 16%|█▋        | 67707/414113 [00:16<01:21, 4270.08it/s]\u001b[A\n",
      " 16%|█▋        | 68135/414113 [00:16<01:24, 4093.45it/s]\u001b[A\n",
      " 17%|█▋        | 68546/414113 [00:16<01:24, 4089.86it/s]\u001b[A\n",
      " 17%|█▋        | 68968/414113 [00:16<01:23, 4126.29it/s]\u001b[A\n",
      " 17%|█▋        | 69388/414113 [00:16<01:23, 4145.96it/s]\u001b[A\n",
      " 17%|█▋        | 69804/414113 [00:16<01:23, 4121.32it/s]\u001b[A\n",
      " 17%|█▋        | 70234/414113 [00:16<01:22, 4170.91it/s]\u001b[A\n",
      " 17%|█▋        | 70652/414113 [00:16<01:24, 4081.67it/s]\u001b[A\n",
      " 17%|█▋        | 71082/414113 [00:16<01:22, 4143.80it/s]\u001b[A\n",
      " 17%|█▋        | 71527/414113 [00:16<01:20, 4230.05it/s]\u001b[A\n",
      " 17%|█▋        | 71967/414113 [00:17<01:19, 4278.60it/s]\u001b[A\n",
      " 17%|█▋        | 72396/414113 [00:17<01:20, 4269.79it/s]\u001b[A\n",
      " 18%|█▊        | 72824/414113 [00:17<01:20, 4257.08it/s]\u001b[A\n",
      " 18%|█▊        | 73251/414113 [00:17<01:20, 4231.92it/s]\u001b[A\n",
      " 18%|█▊        | 73680/414113 [00:17<01:20, 4247.51it/s]\u001b[A\n",
      " 18%|█▊        | 74105/414113 [00:17<01:20, 4245.39it/s]\u001b[A\n",
      " 18%|█▊        | 74530/414113 [00:17<02:10, 2610.75it/s]\u001b[A\n",
      " 18%|█▊        | 74949/414113 [00:17<01:55, 2942.45it/s]\u001b[A\n",
      " 18%|█▊        | 75375/414113 [00:18<01:44, 3243.15it/s]\u001b[A\n",
      " 18%|█▊        | 75809/414113 [00:18<01:36, 3507.63it/s]\u001b[A\n",
      " 18%|█▊        | 76224/414113 [00:18<01:31, 3676.10it/s]\u001b[A\n",
      " 19%|█▊        | 76652/414113 [00:18<01:27, 3836.40it/s]\u001b[A\n",
      " 19%|█▊        | 77075/414113 [00:18<01:25, 3946.07it/s]\u001b[A\n",
      " 19%|█▊        | 77503/414113 [00:18<01:23, 4038.52it/s]\u001b[A\n",
      " 19%|█▉        | 77921/414113 [00:18<01:23, 4048.16it/s]\u001b[A\n",
      " 19%|█▉        | 78341/414113 [00:18<01:22, 4091.79it/s]\u001b[A\n",
      " 19%|█▉        | 78792/414113 [00:18<01:19, 4207.22it/s]\u001b[A\n",
      " 19%|█▉        | 79233/414113 [00:18<01:18, 4264.67it/s]\u001b[A\n",
      " 19%|█▉        | 79665/414113 [00:19<01:18, 4279.97it/s]\u001b[A\n",
      " 19%|█▉        | 80096/414113 [00:19<01:19, 4216.30it/s]\u001b[A\n",
      " 19%|█▉        | 80531/414113 [00:19<01:18, 4254.34it/s]\u001b[A\n",
      " 20%|█▉        | 80963/414113 [00:19<01:17, 4271.72it/s]\u001b[A\n",
      " 20%|█▉        | 81398/414113 [00:19<01:17, 4293.91it/s]\u001b[A\n",
      " 20%|█▉        | 81829/414113 [00:19<01:17, 4286.12it/s]\u001b[A\n",
      " 20%|█▉        | 82273/414113 [00:19<01:16, 4329.71it/s]\u001b[A\n",
      " 20%|█▉        | 82707/414113 [00:19<01:16, 4323.05it/s]\u001b[A\n",
      " 20%|██        | 83161/414113 [00:19<01:15, 4384.49it/s]\u001b[A\n",
      " 20%|██        | 83611/414113 [00:19<01:14, 4415.75it/s]\u001b[A\n",
      " 20%|██        | 84053/414113 [00:20<01:14, 4414.28it/s]\u001b[A\n",
      " 20%|██        | 84495/414113 [00:20<01:15, 4363.06it/s]\u001b[A\n",
      " 21%|██        | 84932/414113 [00:20<01:15, 4345.64it/s]\u001b[A\n",
      " 21%|██        | 85367/414113 [00:20<01:16, 4290.88it/s]\u001b[A\n",
      " 21%|██        | 85797/414113 [00:20<01:16, 4270.26it/s]\u001b[A\n",
      " 21%|██        | 86225/414113 [00:20<01:17, 4251.92it/s]\u001b[A\n",
      " 21%|██        | 86664/414113 [00:20<01:16, 4291.60it/s]\u001b[A\n",
      " 21%|██        | 87094/414113 [00:20<01:16, 4260.56it/s]\u001b[A\n",
      " 21%|██        | 87535/414113 [00:20<01:15, 4302.71it/s]\u001b[A\n",
      " 21%|██        | 87973/414113 [00:20<01:15, 4324.64it/s]\u001b[A\n",
      " 21%|██▏       | 88416/414113 [00:21<01:14, 4354.05it/s]\u001b[A\n",
      " 21%|██▏       | 88852/414113 [00:21<01:14, 4353.72it/s]\u001b[A\n",
      " 22%|██▏       | 89292/414113 [00:21<01:14, 4366.39it/s]\u001b[A\n",
      " 22%|██▏       | 89729/414113 [00:21<01:15, 4319.53it/s]\u001b[A\n",
      " 22%|██▏       | 90162/414113 [00:21<01:15, 4307.68it/s]\u001b[A\n",
      " 22%|██▏       | 90593/414113 [00:21<01:15, 4292.63it/s]\u001b[A\n",
      " 22%|██▏       | 91023/414113 [00:21<01:15, 4278.48it/s]\u001b[A\n",
      " 22%|██▏       | 91466/414113 [00:21<01:14, 4320.11it/s]\u001b[A\n",
      " 22%|██▏       | 91907/414113 [00:21<01:14, 4344.25it/s]\u001b[A\n",
      " 22%|██▏       | 92342/414113 [00:21<01:14, 4333.95it/s]\u001b[A\n",
      " 22%|██▏       | 92776/414113 [00:22<01:14, 4298.75it/s]\u001b[A\n",
      " 23%|██▎       | 93207/414113 [00:22<01:15, 4258.20it/s]\u001b[A\n",
      " 23%|██▎       | 93634/414113 [00:22<01:15, 4260.86it/s]\u001b[A\n",
      " 23%|██▎       | 94065/414113 [00:22<01:14, 4275.10it/s]\u001b[A\n",
      " 23%|██▎       | 94495/414113 [00:22<01:14, 4281.54it/s]\u001b[A\n",
      " 23%|██▎       | 94924/414113 [00:22<01:14, 4268.25it/s]\u001b[A\n",
      " 23%|██▎       | 95351/414113 [00:22<01:15, 4243.28it/s]\u001b[A\n",
      " 23%|██▎       | 95792/414113 [00:22<01:14, 4288.99it/s]\u001b[A\n",
      " 23%|██▎       | 96223/414113 [00:22<01:14, 4292.72it/s]\u001b[A\n",
      " 23%|██▎       | 96676/414113 [00:22<01:12, 4358.38it/s]\u001b[A\n",
      " 23%|██▎       | 97113/414113 [00:23<01:12, 4353.84it/s]\u001b[A\n",
      " 24%|██▎       | 97549/414113 [00:23<01:12, 4344.44it/s]\u001b[A\n",
      " 24%|██▎       | 97990/414113 [00:23<01:12, 4361.20it/s]\u001b[A\n",
      " 24%|██▍       | 98427/414113 [00:23<01:12, 4327.90it/s]\u001b[A\n",
      " 24%|██▍       | 98860/414113 [00:23<01:13, 4278.36it/s]\u001b[A\n",
      " 24%|██▍       | 99289/414113 [00:23<01:15, 4196.08it/s]\u001b[A\n",
      " 24%|██▍       | 99730/414113 [00:23<01:13, 4254.03it/s]\u001b[A\n",
      " 24%|██▍       | 100156/414113 [00:23<01:13, 4253.62it/s]\u001b[A\n",
      " 24%|██▍       | 100582/414113 [00:23<01:13, 4243.85it/s]\u001b[A\n",
      " 24%|██▍       | 101015/414113 [00:24<01:13, 4268.67it/s]\u001b[A\n",
      " 24%|██▍       | 101443/414113 [00:24<01:13, 4226.67it/s]\u001b[A\n",
      " 25%|██▍       | 101870/414113 [00:24<01:13, 4237.44it/s]\u001b[A\n",
      " 25%|██▍       | 102294/414113 [00:24<01:13, 4223.91it/s]\u001b[A\n",
      " 25%|██▍       | 102721/414113 [00:24<01:13, 4236.20it/s]\u001b[A\n",
      " 25%|██▍       | 103145/414113 [00:24<01:13, 4205.12it/s]\u001b[A\n",
      " 25%|██▌       | 103576/414113 [00:24<01:13, 4235.62it/s]\u001b[A\n",
      " 25%|██▌       | 104008/414113 [00:24<01:12, 4258.69it/s]\u001b[A\n",
      " 25%|██▌       | 104434/414113 [00:24<01:13, 4241.35it/s]\u001b[A\n",
      " 25%|██▌       | 104859/414113 [00:24<01:13, 4236.03it/s]\u001b[A\n",
      " 25%|██▌       | 105296/414113 [00:25<01:12, 4275.08it/s]\u001b[A\n",
      " 26%|██▌       | 105727/414113 [00:25<01:11, 4284.21it/s]\u001b[A\n",
      " 26%|██▌       | 106162/414113 [00:25<01:11, 4302.16it/s]\u001b[A\n",
      " 26%|██▌       | 106602/414113 [00:25<01:11, 4328.95it/s]\u001b[A\n",
      " 26%|██▌       | 107038/414113 [00:25<01:10, 4338.12it/s]\u001b[A\n",
      " 26%|██▌       | 107473/414113 [00:25<01:10, 4340.13it/s]\u001b[A\n",
      " 26%|██▌       | 107908/414113 [00:25<01:10, 4313.48it/s]\u001b[A\n",
      " 26%|██▌       | 108352/414113 [00:25<01:10, 4349.85it/s]\u001b[A\n",
      " 26%|██▋       | 108794/414113 [00:25<01:09, 4367.83it/s]\u001b[A\n",
      " 26%|██▋       | 109231/414113 [00:25<01:10, 4296.69it/s]\u001b[A\n",
      " 26%|██▋       | 109664/414113 [00:26<01:10, 4305.75it/s]\u001b[A\n",
      " 27%|██▋       | 110109/414113 [00:26<01:09, 4345.00it/s]\u001b[A\n",
      " 27%|██▋       | 110544/414113 [00:26<01:10, 4330.48it/s]\u001b[A\n",
      " 27%|██▋       | 110978/414113 [00:26<01:11, 4266.82it/s]\u001b[A\n",
      " 27%|██▋       | 111406/414113 [00:26<01:10, 4264.05it/s]\u001b[A\n",
      " 27%|██▋       | 111833/414113 [00:26<01:10, 4265.00it/s]\u001b[A\n",
      " 27%|██▋       | 112272/414113 [00:26<01:10, 4299.38it/s]\u001b[A\n",
      " 27%|██▋       | 112714/414113 [00:26<01:09, 4331.97it/s]\u001b[A\n",
      " 27%|██▋       | 113159/414113 [00:26<01:08, 4365.98it/s]\u001b[A\n",
      " 27%|██▋       | 113608/414113 [00:26<01:08, 4402.08it/s]\u001b[A\n",
      " 28%|██▊       | 114049/414113 [00:27<01:08, 4394.58it/s]\u001b[A\n",
      " 28%|██▊       | 114489/414113 [00:27<01:08, 4369.75it/s]\u001b[A\n",
      " 28%|██▊       | 114932/414113 [00:27<01:08, 4387.13it/s]\u001b[A\n",
      " 28%|██▊       | 115371/414113 [00:27<01:09, 4321.28it/s]\u001b[A\n",
      " 28%|██▊       | 115805/414113 [00:27<01:08, 4324.26it/s]\u001b[A\n",
      " 28%|██▊       | 116238/414113 [00:27<01:10, 4249.66it/s]\u001b[A\n",
      " 28%|██▊       | 116677/414113 [00:27<01:09, 4289.66it/s]\u001b[A\n",
      " 28%|██▊       | 117107/414113 [00:27<01:09, 4251.48it/s]\u001b[A\n",
      " 28%|██▊       | 117536/414113 [00:27<01:09, 4262.11it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 117963/414113 [00:27<01:09, 4247.40it/s]\u001b[A\n",
      " 29%|██▊       | 118388/414113 [00:28<01:09, 4247.95it/s]\u001b[A\n",
      " 29%|██▊       | 118819/414113 [00:28<01:09, 4263.95it/s]\u001b[A\n",
      " 29%|██▉       | 119246/414113 [00:28<01:11, 4114.67it/s]\u001b[A\n",
      " 29%|██▉       | 119659/414113 [00:28<01:16, 3864.82it/s]\u001b[A\n",
      " 29%|██▉       | 120091/414113 [00:28<01:13, 3990.04it/s]\u001b[A\n",
      " 29%|██▉       | 120521/414113 [00:28<01:12, 4076.91it/s]\u001b[A\n",
      " 29%|██▉       | 120953/414113 [00:28<01:10, 4145.07it/s]\u001b[A\n",
      " 29%|██▉       | 121386/414113 [00:28<01:09, 4196.98it/s]\u001b[A\n",
      " 29%|██▉       | 121824/414113 [00:28<01:08, 4248.89it/s]\u001b[A\n",
      " 30%|██▉       | 122251/414113 [00:28<01:09, 4229.09it/s]\u001b[A\n",
      " 30%|██▉       | 122694/414113 [00:29<01:08, 4284.54it/s]\u001b[A\n",
      " 30%|██▉       | 123124/414113 [00:29<01:08, 4267.83it/s]\u001b[A\n",
      " 30%|██▉       | 123559/414113 [00:29<01:07, 4290.42it/s]\u001b[A\n",
      " 30%|██▉       | 123991/414113 [00:29<01:07, 4297.21it/s]\u001b[A\n",
      " 30%|███       | 124422/414113 [00:29<01:07, 4280.16it/s]\u001b[A\n",
      " 30%|███       | 124865/414113 [00:29<01:06, 4322.10it/s]\u001b[A\n",
      " 30%|███       | 125306/414113 [00:29<01:06, 4347.67it/s]\u001b[A\n",
      " 30%|███       | 125742/414113 [00:29<01:06, 4350.45it/s]\u001b[A\n",
      " 30%|███       | 126178/414113 [00:29<01:08, 4200.39it/s]\u001b[A\n",
      " 31%|███       | 126613/414113 [00:30<01:07, 4242.39it/s]\u001b[A\n",
      " 31%|███       | 127058/414113 [00:30<01:06, 4300.45it/s]\u001b[A\n",
      " 31%|███       | 127489/414113 [00:30<01:06, 4286.33it/s]\u001b[A\n",
      " 31%|███       | 127919/414113 [00:30<01:06, 4279.19it/s]\u001b[A\n",
      " 31%|███       | 128354/414113 [00:30<01:06, 4299.73it/s]\u001b[A\n",
      " 31%|███       | 128796/414113 [00:30<01:05, 4334.88it/s]\u001b[A\n",
      " 31%|███       | 129241/414113 [00:30<01:05, 4367.15it/s]\u001b[A\n",
      " 31%|███▏      | 129678/414113 [00:30<01:05, 4365.77it/s]\u001b[A\n",
      " 31%|███▏      | 130115/414113 [00:30<01:05, 4338.58it/s]\u001b[A\n",
      " 32%|███▏      | 130554/414113 [00:30<01:05, 4353.20it/s]\u001b[A\n",
      " 32%|███▏      | 130991/414113 [00:31<01:04, 4357.67it/s]\u001b[A\n",
      " 32%|███▏      | 131438/414113 [00:31<01:04, 4390.52it/s]\u001b[A\n",
      " 32%|███▏      | 131878/414113 [00:31<01:04, 4379.53it/s]\u001b[A\n",
      " 32%|███▏      | 132317/414113 [00:31<01:05, 4294.84it/s]\u001b[A\n",
      " 32%|███▏      | 132747/414113 [00:31<01:07, 4185.51it/s]\u001b[A\n",
      " 32%|███▏      | 133188/414113 [00:31<01:06, 4248.38it/s]\u001b[A\n",
      " 32%|███▏      | 133638/414113 [00:31<01:04, 4318.96it/s]\u001b[A\n",
      " 32%|███▏      | 134071/414113 [00:31<01:04, 4313.12it/s]\u001b[A\n",
      " 32%|███▏      | 134503/414113 [00:31<01:05, 4270.70it/s]\u001b[A\n",
      " 33%|███▎      | 134931/414113 [00:31<01:06, 4221.96it/s]\u001b[A\n",
      " 33%|███▎      | 135359/414113 [00:32<01:05, 4237.57it/s]\u001b[A\n",
      " 33%|███▎      | 135813/414113 [00:32<01:04, 4323.13it/s]\u001b[A\n",
      " 33%|███▎      | 136256/414113 [00:32<01:03, 4354.46it/s]\u001b[A\n",
      " 33%|███▎      | 136692/414113 [00:32<01:04, 4319.81it/s]\u001b[A\n",
      " 33%|███▎      | 137125/414113 [00:32<01:04, 4310.05it/s]\u001b[A\n",
      " 33%|███▎      | 137559/414113 [00:32<01:04, 4318.58it/s]\u001b[A\n",
      " 33%|███▎      | 137994/414113 [00:32<01:03, 4326.74it/s]\u001b[A\n",
      " 33%|███▎      | 138427/414113 [00:32<01:04, 4290.66it/s]\u001b[A\n",
      " 34%|███▎      | 138857/414113 [00:32<01:04, 4280.13it/s]\u001b[A\n",
      " 34%|███▎      | 139290/414113 [00:32<01:04, 4292.30it/s]\u001b[A\n",
      " 34%|███▎      | 139736/414113 [00:33<01:03, 4340.79it/s]\u001b[A\n",
      " 34%|███▍      | 140171/414113 [00:33<01:03, 4320.27it/s]\u001b[A\n",
      " 34%|███▍      | 140604/414113 [00:33<01:03, 4321.85it/s]\u001b[A\n",
      " 34%|███▍      | 141037/414113 [00:33<01:03, 4294.63it/s]\u001b[A\n",
      " 34%|███▍      | 141467/414113 [00:33<01:03, 4278.17it/s]\u001b[A\n",
      " 34%|███▍      | 141903/414113 [00:33<01:03, 4299.79it/s]\u001b[A\n",
      " 34%|███▍      | 142335/414113 [00:33<01:03, 4303.53it/s]\u001b[A\n",
      " 34%|███▍      | 142766/414113 [00:33<01:03, 4292.20it/s]\u001b[A\n",
      " 35%|███▍      | 143198/414113 [00:33<01:03, 4299.92it/s]\u001b[A\n",
      " 35%|███▍      | 143646/414113 [00:33<01:02, 4349.91it/s]\u001b[A\n",
      " 35%|███▍      | 144082/414113 [00:34<01:02, 4337.83it/s]\u001b[A\n",
      " 35%|███▍      | 144517/414113 [00:34<01:02, 4338.27it/s]\u001b[A\n",
      " 35%|███▌      | 144951/414113 [00:34<01:02, 4323.05it/s]\u001b[A\n",
      " 35%|███▌      | 145384/414113 [00:34<01:02, 4310.81it/s]\u001b[A\n",
      " 35%|███▌      | 145824/414113 [00:34<01:01, 4334.68it/s]\u001b[A\n",
      " 35%|███▌      | 146258/414113 [00:34<01:02, 4316.24it/s]\u001b[A\n",
      " 35%|███▌      | 146690/414113 [00:34<01:02, 4305.99it/s]\u001b[A\n",
      " 36%|███▌      | 147121/414113 [00:34<01:02, 4297.80it/s]\u001b[A\n",
      " 36%|███▌      | 147551/414113 [00:34<01:03, 4218.40it/s]\u001b[A\n",
      " 36%|███▌      | 147974/414113 [00:34<01:03, 4193.59it/s]\u001b[A\n",
      " 36%|███▌      | 148398/414113 [00:35<01:03, 4204.39it/s]\u001b[A\n",
      " 36%|███▌      | 148819/414113 [00:35<01:03, 4183.46it/s]\u001b[A\n",
      " 36%|███▌      | 149255/414113 [00:35<01:02, 4231.64it/s]\u001b[A\n",
      " 36%|███▌      | 149679/414113 [00:35<01:02, 4207.77it/s]\u001b[A\n",
      " 36%|███▌      | 150100/414113 [00:35<01:02, 4201.03it/s]\u001b[A\n",
      " 36%|███▋      | 150524/414113 [00:35<01:02, 4210.24it/s]\u001b[A\n",
      " 36%|███▋      | 150946/414113 [00:35<01:02, 4205.72it/s]\u001b[A\n",
      " 37%|███▋      | 151367/414113 [00:35<01:02, 4172.12it/s]\u001b[A\n",
      " 37%|███▋      | 151785/414113 [00:35<01:03, 4163.07it/s]\u001b[A\n",
      " 37%|███▋      | 152202/414113 [00:35<01:04, 4055.84it/s]\u001b[A\n",
      " 37%|███▋      | 152643/414113 [00:36<01:02, 4153.92it/s]\u001b[A\n",
      " 37%|███▋      | 153062/414113 [00:36<01:02, 4161.38it/s]\u001b[A\n",
      " 37%|███▋      | 153496/414113 [00:36<01:01, 4211.65it/s]\u001b[A\n",
      " 37%|███▋      | 153943/414113 [00:36<01:00, 4284.40it/s]\u001b[A\n",
      " 37%|███▋      | 154384/414113 [00:36<01:00, 4319.80it/s]\u001b[A\n",
      " 37%|███▋      | 154817/414113 [00:36<01:00, 4271.09it/s]\u001b[A\n",
      " 37%|███▋      | 155245/414113 [00:36<01:00, 4250.99it/s]\u001b[A\n",
      " 38%|███▊      | 155687/414113 [00:36<01:00, 4299.26it/s]\u001b[A\n",
      " 38%|███▊      | 156138/414113 [00:36<00:59, 4358.23it/s]\u001b[A\n",
      " 38%|███▊      | 156590/414113 [00:36<00:58, 4404.61it/s]\u001b[A\n",
      " 38%|███▊      | 157037/414113 [00:37<00:58, 4419.75it/s]\u001b[A\n",
      " 38%|███▊      | 157480/414113 [00:37<00:59, 4327.49it/s]\u001b[A\n",
      " 38%|███▊      | 157914/414113 [00:37<00:59, 4307.01it/s]\u001b[A\n",
      " 38%|███▊      | 158359/414113 [00:37<00:58, 4347.51it/s]\u001b[A\n",
      " 38%|███▊      | 158795/414113 [00:37<00:58, 4342.44it/s]\u001b[A\n",
      " 38%|███▊      | 159230/414113 [00:37<00:59, 4254.75it/s]\u001b[A\n",
      " 39%|███▊      | 159657/414113 [00:37<01:01, 4150.61it/s]\u001b[A\n",
      " 39%|███▊      | 160074/414113 [00:37<01:01, 4127.28it/s]\u001b[A\n",
      " 39%|███▉      | 160492/414113 [00:37<01:01, 4141.88it/s]\u001b[A\n",
      " 39%|███▉      | 160942/414113 [00:38<00:59, 4239.87it/s]\u001b[A\n",
      " 39%|███▉      | 161394/414113 [00:38<00:58, 4319.05it/s]\u001b[A\n",
      " 39%|███▉      | 161827/414113 [00:38<00:58, 4311.93it/s]\u001b[A\n",
      " 39%|███▉      | 162268/414113 [00:38<00:58, 4340.54it/s]\u001b[A\n",
      " 39%|███▉      | 162722/414113 [00:38<00:57, 4396.60it/s]\u001b[A\n",
      " 39%|███▉      | 163163/414113 [00:38<00:58, 4318.95it/s]\u001b[A\n",
      " 40%|███▉      | 163596/414113 [00:38<00:58, 4301.06it/s]\u001b[A\n",
      " 40%|███▉      | 164027/414113 [00:38<00:59, 4175.82it/s]\u001b[A\n",
      " 40%|███▉      | 164446/414113 [00:38<01:01, 4085.16it/s]\u001b[A\n",
      " 40%|███▉      | 164856/414113 [00:38<01:02, 4000.06it/s]\u001b[A\n",
      " 40%|███▉      | 165258/414113 [00:39<01:02, 3974.99it/s]\u001b[A\n",
      " 40%|████      | 165678/414113 [00:39<01:01, 4037.66it/s]\u001b[A\n",
      " 40%|████      | 166083/414113 [00:39<01:01, 4022.42it/s]\u001b[A\n",
      " 40%|████      | 166489/414113 [00:39<01:01, 4032.48it/s]\u001b[A\n",
      " 40%|████      | 166906/414113 [00:39<01:00, 4072.58it/s]\u001b[A\n",
      " 40%|████      | 167318/414113 [00:39<01:00, 4085.11it/s]\u001b[A\n",
      " 41%|████      | 167727/414113 [00:40<02:06, 1954.23it/s]\u001b[A\n",
      " 41%|████      | 168163/414113 [00:40<01:45, 2341.12it/s]\u001b[A\n",
      " 41%|████      | 168605/414113 [00:40<01:30, 2725.69it/s]\u001b[A\n",
      " 41%|████      | 169022/414113 [00:40<01:20, 3041.71it/s]\u001b[A\n",
      " 41%|████      | 169448/414113 [00:40<01:13, 3325.98it/s]\u001b[A\n",
      " 41%|████      | 169869/414113 [00:40<01:08, 3548.27it/s]\u001b[A\n",
      " 41%|████      | 170284/414113 [00:40<01:05, 3708.99it/s]\u001b[A\n",
      " 41%|████      | 170714/414113 [00:40<01:02, 3867.32it/s]\u001b[A\n",
      " 41%|████▏     | 171134/414113 [00:40<01:01, 3959.20it/s]\u001b[A\n",
      " 41%|████▏     | 171563/414113 [00:40<00:59, 4051.10it/s]\u001b[A\n",
      " 42%|████▏     | 171983/414113 [00:41<00:59, 4093.71it/s]\u001b[A\n",
      " 42%|████▏     | 172405/414113 [00:41<00:58, 4129.81it/s]\u001b[A\n",
      " 42%|████▏     | 172829/414113 [00:41<00:57, 4160.48it/s]\u001b[A\n",
      " 42%|████▏     | 173251/414113 [00:41<00:57, 4163.30it/s]\u001b[A\n",
      " 42%|████▏     | 173671/414113 [00:41<00:57, 4163.38it/s]\u001b[A\n",
      " 42%|████▏     | 174098/414113 [00:41<00:57, 4192.47it/s]\u001b[A\n",
      " 42%|████▏     | 174520/414113 [00:41<00:57, 4183.91it/s]\u001b[A\n",
      " 42%|████▏     | 174940/414113 [00:41<01:36, 2480.21it/s]\u001b[A\n",
      " 42%|████▏     | 175355/414113 [00:42<01:24, 2819.51it/s]\u001b[A\n",
      " 42%|████▏     | 175776/414113 [00:42<01:16, 3129.29it/s]\u001b[A\n",
      " 43%|████▎     | 176209/414113 [00:42<01:09, 3412.46it/s]\u001b[A\n",
      " 43%|████▎     | 176631/414113 [00:42<01:05, 3619.20it/s]\u001b[A\n",
      " 43%|████▎     | 177078/414113 [00:42<01:01, 3837.75it/s]\u001b[A\n",
      " 43%|████▎     | 177513/414113 [00:42<00:59, 3976.32it/s]\u001b[A\n",
      " 43%|████▎     | 177949/414113 [00:42<00:57, 4081.93it/s]\u001b[A\n",
      " 43%|████▎     | 178375/414113 [00:42<00:57, 4089.63it/s]\u001b[A\n",
      " 43%|████▎     | 178806/414113 [00:42<00:56, 4153.06it/s]\u001b[A\n",
      " 43%|████▎     | 179230/414113 [00:42<00:56, 4158.13it/s]\u001b[A\n",
      " 43%|████▎     | 179658/414113 [00:43<00:55, 4190.99it/s]\u001b[A\n",
      " 43%|████▎     | 180082/414113 [00:43<00:56, 4171.87it/s]\u001b[A\n",
      " 44%|████▎     | 180503/414113 [00:43<00:55, 4176.41it/s]\u001b[A\n",
      " 44%|████▎     | 180923/414113 [00:43<00:55, 4177.50it/s]\u001b[A\n",
      " 44%|████▍     | 181350/414113 [00:43<00:55, 4203.20it/s]\u001b[A\n",
      " 44%|████▍     | 181775/414113 [00:43<00:55, 4214.73it/s]\u001b[A\n",
      " 44%|████▍     | 182204/414113 [00:43<00:54, 4236.88it/s]\u001b[A\n",
      " 44%|████▍     | 182633/414113 [00:43<00:54, 4251.20it/s]\u001b[A\n",
      " 44%|████▍     | 183059/414113 [00:43<00:54, 4233.05it/s]\u001b[A\n",
      " 44%|████▍     | 183483/414113 [00:43<00:54, 4206.41it/s]\u001b[A\n",
      " 44%|████▍     | 183904/414113 [00:44<00:55, 4183.18it/s]\u001b[A\n",
      " 45%|████▍     | 184326/414113 [00:44<00:54, 4191.74it/s]\u001b[A\n",
      " 45%|████▍     | 184747/414113 [00:44<00:54, 4195.58it/s]\u001b[A\n",
      " 45%|████▍     | 185177/414113 [00:44<00:54, 4223.43it/s]\u001b[A\n",
      " 45%|████▍     | 185605/414113 [00:44<00:53, 4237.81it/s]\u001b[A\n",
      " 45%|████▍     | 186029/414113 [00:44<00:54, 4204.29it/s]\u001b[A\n",
      " 45%|████▌     | 186459/414113 [00:44<00:53, 4231.23it/s]\u001b[A\n",
      " 45%|████▌     | 186898/414113 [00:44<00:53, 4277.39it/s]\u001b[A\n",
      " 45%|████▌     | 187326/414113 [00:44<00:53, 4276.19it/s]\u001b[A\n",
      " 45%|████▌     | 187765/414113 [00:44<00:52, 4309.38it/s]\u001b[A\n",
      " 45%|████▌     | 188197/414113 [00:45<00:52, 4297.28it/s]\u001b[A\n",
      " 46%|████▌     | 188627/414113 [00:45<00:53, 4205.21it/s]\u001b[A\n",
      " 46%|████▌     | 189055/414113 [00:45<00:53, 4226.32it/s]\u001b[A\n",
      " 46%|████▌     | 189485/414113 [00:45<00:52, 4245.53it/s]\u001b[A\n",
      " 46%|████▌     | 189910/414113 [00:45<00:53, 4221.02it/s]\u001b[A\n",
      " 46%|████▌     | 190350/414113 [00:45<00:52, 4272.19it/s]\u001b[A\n",
      " 46%|████▌     | 190782/414113 [00:45<00:52, 4284.72it/s]\u001b[A\n",
      " 46%|████▌     | 191211/414113 [00:45<00:52, 4255.80it/s]\u001b[A\n",
      " 46%|████▋     | 191637/414113 [00:45<00:52, 4210.71it/s]\u001b[A\n",
      " 46%|████▋     | 192060/414113 [00:45<00:52, 4216.26it/s]\u001b[A\n",
      " 46%|████▋     | 192490/414113 [00:46<00:52, 4239.38it/s]\u001b[A\n",
      " 47%|████▋     | 192915/414113 [00:46<00:52, 4215.22it/s]\u001b[A\n",
      " 47%|████▋     | 193337/414113 [00:46<00:52, 4184.88it/s]\u001b[A\n",
      " 47%|████▋     | 193782/414113 [00:46<00:51, 4258.52it/s]\u001b[A\n",
      " 47%|████▋     | 194209/414113 [00:46<00:51, 4259.03it/s]\u001b[A\n",
      " 47%|████▋     | 194641/414113 [00:46<00:51, 4274.97it/s]\u001b[A\n",
      " 47%|████▋     | 195069/414113 [00:46<00:51, 4238.04it/s]\u001b[A\n",
      " 47%|████▋     | 195506/414113 [00:46<00:51, 4273.98it/s]\u001b[A\n",
      " 47%|████▋     | 195935/414113 [00:46<00:51, 4276.81it/s]\u001b[A\n",
      " 47%|████▋     | 196363/414113 [00:47<00:50, 4273.57it/s]\u001b[A\n",
      " 48%|████▊     | 196798/414113 [00:47<00:50, 4293.92it/s]\u001b[A\n",
      " 48%|████▊     | 197230/414113 [00:47<00:50, 4300.69it/s]\u001b[A\n",
      " 48%|████▊     | 197661/414113 [00:47<00:50, 4259.98it/s]\u001b[A\n",
      " 48%|████▊     | 198094/414113 [00:47<00:50, 4280.11it/s]\u001b[A\n",
      " 48%|████▊     | 198523/414113 [00:47<00:50, 4274.58it/s]\u001b[A\n",
      " 48%|████▊     | 198961/414113 [00:47<00:49, 4303.43it/s]\u001b[A\n",
      " 48%|████▊     | 199392/414113 [00:47<00:51, 4142.42it/s]\u001b[A\n",
      " 48%|████▊     | 199817/414113 [00:47<00:51, 4170.24it/s]\u001b[A\n",
      " 48%|████▊     | 200236/414113 [00:47<00:51, 4163.35it/s]\u001b[A\n",
      " 48%|████▊     | 200677/414113 [00:48<00:50, 4231.62it/s]\u001b[A\n",
      " 49%|████▊     | 201108/414113 [00:48<00:50, 4252.73it/s]\u001b[A\n",
      " 49%|████▊     | 201547/414113 [00:48<00:49, 4290.62it/s]\u001b[A\n",
      " 49%|████▉     | 201984/414113 [00:48<00:49, 4313.62it/s]\u001b[A\n",
      " 49%|████▉     | 202425/414113 [00:48<00:48, 4340.47it/s]\u001b[A\n",
      " 49%|████▉     | 202863/414113 [00:48<00:48, 4350.48it/s]\u001b[A\n",
      " 49%|████▉     | 203305/414113 [00:48<00:48, 4368.52it/s]\u001b[A\n",
      " 49%|████▉     | 203743/414113 [00:48<00:48, 4318.67it/s]\u001b[A\n",
      " 49%|████▉     | 204184/414113 [00:48<00:48, 4343.20it/s]\u001b[A\n",
      " 49%|████▉     | 204630/414113 [00:48<00:47, 4375.02it/s]\u001b[A\n",
      " 50%|████▉     | 205068/414113 [00:49<00:47, 4373.39it/s]\u001b[A\n",
      " 50%|████▉     | 205506/414113 [00:49<00:48, 4315.23it/s]\u001b[A\n",
      " 50%|████▉     | 205938/414113 [00:49<00:48, 4297.63it/s]\u001b[A\n",
      " 50%|████▉     | 206368/414113 [00:49<00:51, 4037.97it/s]\u001b[A\n",
      " 50%|████▉     | 206813/414113 [00:49<00:49, 4152.13it/s]\u001b[A\n",
      " 50%|█████     | 207244/414113 [00:49<00:49, 4197.52it/s]\u001b[A\n",
      " 50%|█████     | 207682/414113 [00:49<00:48, 4249.13it/s]\u001b[A\n",
      " 50%|█████     | 208109/414113 [00:49<00:48, 4255.21it/s]\u001b[A\n",
      " 50%|█████     | 208536/414113 [00:49<00:48, 4211.57it/s]\u001b[A\n",
      " 50%|█████     | 208975/414113 [00:49<00:48, 4262.65it/s]\u001b[A\n",
      " 51%|█████     | 209414/414113 [00:50<00:47, 4299.43it/s]\u001b[A\n",
      " 51%|█████     | 209851/414113 [00:50<00:47, 4320.18it/s]\u001b[A\n",
      " 51%|█████     | 210292/414113 [00:50<00:46, 4344.10it/s]\u001b[A\n",
      " 51%|█████     | 210727/414113 [00:50<00:46, 4331.75it/s]\u001b[A\n",
      " 51%|█████     | 211172/414113 [00:50<00:46, 4365.04it/s]\u001b[A\n",
      " 51%|█████     | 211618/414113 [00:50<00:46, 4390.56it/s]\u001b[A\n",
      " 51%|█████     | 212058/414113 [00:50<00:46, 4369.80it/s]\u001b[A\n",
      " 51%|█████▏    | 212496/414113 [00:50<00:46, 4319.70it/s]\u001b[A\n",
      " 51%|█████▏    | 212929/414113 [00:50<00:46, 4311.25it/s]\u001b[A\n",
      " 52%|█████▏    | 213363/414113 [00:50<00:46, 4319.29it/s]\u001b[A\n",
      " 52%|█████▏    | 213801/414113 [00:51<00:46, 4335.68it/s]\u001b[A\n",
      " 52%|█████▏    | 214235/414113 [00:51<00:46, 4324.07it/s]\u001b[A\n",
      " 52%|█████▏    | 214668/414113 [00:51<00:46, 4314.25it/s]\u001b[A\n",
      " 52%|█████▏    | 215102/414113 [00:51<00:46, 4321.20it/s]\u001b[A\n",
      " 52%|█████▏    | 215545/414113 [00:51<00:45, 4352.17it/s]\u001b[A\n",
      " 52%|█████▏    | 215981/414113 [00:51<00:45, 4347.90it/s]\u001b[A\n",
      " 52%|█████▏    | 216419/414113 [00:51<00:45, 4355.00it/s]\u001b[A\n",
      " 52%|█████▏    | 216855/414113 [00:51<00:45, 4328.73it/s]\u001b[A\n",
      " 52%|█████▏    | 217304/414113 [00:51<00:45, 4371.51it/s]\u001b[A\n",
      " 53%|█████▎    | 217759/414113 [00:51<00:44, 4423.26it/s]\u001b[A\n",
      " 53%|█████▎    | 218202/414113 [00:52<00:44, 4400.17it/s]\u001b[A\n",
      " 53%|█████▎    | 218643/414113 [00:52<00:44, 4379.60it/s]\u001b[A\n",
      " 53%|█████▎    | 219082/414113 [00:52<00:44, 4365.82it/s]\u001b[A\n",
      " 53%|█████▎    | 219529/414113 [00:52<00:44, 4394.58it/s]\u001b[A\n",
      " 53%|█████▎    | 219969/414113 [00:52<00:44, 4394.94it/s]\u001b[A\n",
      " 53%|█████▎    | 220409/414113 [00:52<00:44, 4336.38it/s]\u001b[A\n",
      " 53%|█████▎    | 220843/414113 [00:52<00:44, 4315.53it/s]\u001b[A\n",
      " 53%|█████▎    | 221275/414113 [00:52<00:44, 4294.60it/s]\u001b[A\n",
      " 54%|█████▎    | 221710/414113 [00:52<00:44, 4309.23it/s]\u001b[A\n",
      " 54%|█████▎    | 222162/414113 [00:52<00:43, 4369.98it/s]\u001b[A\n",
      " 54%|█████▍    | 222600/414113 [00:53<00:43, 4362.70it/s]\u001b[A\n",
      " 54%|█████▍    | 223037/414113 [00:53<00:43, 4345.89it/s]\u001b[A\n",
      " 54%|█████▍    | 223472/414113 [00:53<00:44, 4328.39it/s]\u001b[A\n",
      " 54%|█████▍    | 223918/414113 [00:53<00:43, 4363.87it/s]\u001b[A\n",
      " 54%|█████▍    | 224355/414113 [00:53<00:43, 4359.32it/s]\u001b[A\n",
      " 54%|█████▍    | 224792/414113 [00:53<00:43, 4361.09it/s]\u001b[A\n",
      " 54%|█████▍    | 225229/414113 [00:53<00:43, 4345.64it/s]\u001b[A\n",
      " 54%|█████▍    | 225664/414113 [00:53<00:43, 4344.77it/s]\u001b[A\n",
      " 55%|█████▍    | 226099/414113 [00:53<00:43, 4298.56it/s]\u001b[A\n",
      " 55%|█████▍    | 226545/414113 [00:53<00:43, 4345.17it/s]\u001b[A\n",
      " 55%|█████▍    | 226980/414113 [00:54<00:43, 4320.34it/s]\u001b[A\n",
      " 55%|█████▍    | 227413/414113 [00:54<00:43, 4300.50it/s]\u001b[A\n",
      " 55%|█████▌    | 227852/414113 [00:54<00:43, 4324.91it/s]\u001b[A\n",
      " 55%|█████▌    | 228300/414113 [00:54<00:42, 4367.73it/s]\u001b[A\n",
      " 55%|█████▌    | 228737/414113 [00:54<00:42, 4351.34it/s]\u001b[A\n",
      " 55%|█████▌    | 229173/414113 [00:54<00:42, 4343.57it/s]\u001b[A\n",
      " 55%|█████▌    | 229608/414113 [00:54<00:42, 4309.42it/s]\u001b[A\n",
      " 56%|█████▌    | 230040/414113 [00:54<00:43, 4243.58it/s]\u001b[A\n",
      " 56%|█████▌    | 230467/414113 [00:54<00:43, 4249.13it/s]\u001b[A\n",
      " 56%|█████▌    | 230893/414113 [00:55<00:43, 4221.97it/s]\u001b[A\n",
      " 56%|█████▌    | 231320/414113 [00:55<00:43, 4234.85it/s]\u001b[A\n",
      " 56%|█████▌    | 231744/414113 [00:55<00:43, 4226.91it/s]\u001b[A\n",
      " 56%|█████▌    | 232167/414113 [00:55<00:43, 4162.96it/s]\u001b[A\n",
      " 56%|█████▌    | 232596/414113 [00:55<00:43, 4200.01it/s]\u001b[A\n",
      " 56%|█████▋    | 233017/414113 [00:55<00:43, 4201.50it/s]\u001b[A\n",
      " 56%|█████▋    | 233438/414113 [00:55<00:43, 4131.08it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 233852/414113 [00:55<00:44, 4070.92it/s]\u001b[A\n",
      " 57%|█████▋    | 234285/414113 [00:55<00:43, 4144.36it/s]\u001b[A\n",
      " 57%|█████▋    | 234705/414113 [00:55<00:43, 4158.00it/s]\u001b[A\n",
      " 57%|█████▋    | 235144/414113 [00:56<00:42, 4223.96it/s]\u001b[A\n",
      " 57%|█████▋    | 235574/414113 [00:56<00:42, 4244.46it/s]\u001b[A\n",
      " 57%|█████▋    | 236006/414113 [00:56<00:41, 4264.41it/s]\u001b[A\n",
      " 57%|█████▋    | 236440/414113 [00:56<00:41, 4284.46it/s]\u001b[A\n",
      " 57%|█████▋    | 236869/414113 [00:56<00:41, 4244.73it/s]\u001b[A\n",
      " 57%|█████▋    | 237294/414113 [00:56<00:43, 4094.75it/s]\u001b[A\n",
      " 57%|█████▋    | 237715/414113 [00:56<00:42, 4127.81it/s]\u001b[A\n",
      " 58%|█████▊    | 238131/414113 [00:56<00:42, 4135.28it/s]\u001b[A\n",
      " 58%|█████▊    | 238546/414113 [00:56<00:42, 4117.70it/s]\u001b[A\n",
      " 58%|█████▊    | 238965/414113 [00:56<00:42, 4137.39it/s]\u001b[A\n",
      " 58%|█████▊    | 239383/414113 [00:57<00:42, 4148.20it/s]\u001b[A\n",
      " 58%|█████▊    | 239799/414113 [00:57<00:42, 4136.24it/s]\u001b[A\n",
      " 58%|█████▊    | 240227/414113 [00:57<00:41, 4174.50it/s]\u001b[A\n",
      " 58%|█████▊    | 240656/414113 [00:57<00:41, 4207.75it/s]\u001b[A\n",
      " 58%|█████▊    | 241082/414113 [00:57<00:40, 4220.89it/s]\u001b[A\n",
      " 58%|█████▊    | 241505/414113 [00:57<00:41, 4157.90it/s]\u001b[A\n",
      " 58%|█████▊    | 241929/414113 [00:57<00:41, 4179.95it/s]\u001b[A\n",
      " 59%|█████▊    | 242348/414113 [00:57<00:41, 4098.46it/s]\u001b[A\n",
      " 59%|█████▊    | 242783/414113 [00:57<00:41, 4169.08it/s]\u001b[A\n",
      " 59%|█████▊    | 243223/414113 [00:57<00:40, 4233.37it/s]\u001b[A\n",
      " 59%|█████▉    | 243648/414113 [00:58<00:40, 4233.45it/s]\u001b[A\n",
      " 59%|█████▉    | 244072/414113 [00:58<00:40, 4227.08it/s]\u001b[A\n",
      " 59%|█████▉    | 244514/414113 [00:58<00:39, 4283.16it/s]\u001b[A\n",
      " 59%|█████▉    | 244957/414113 [00:58<00:39, 4323.44it/s]\u001b[A\n",
      " 59%|█████▉    | 245395/414113 [00:58<00:38, 4337.94it/s]\u001b[A\n",
      " 59%|█████▉    | 245830/414113 [00:58<00:39, 4259.27it/s]\u001b[A\n",
      " 59%|█████▉    | 246257/414113 [00:58<00:39, 4216.14it/s]\u001b[A\n",
      " 60%|█████▉    | 246680/414113 [00:58<00:39, 4206.68it/s]\u001b[A\n",
      " 60%|█████▉    | 247101/414113 [00:58<00:39, 4206.90it/s]\u001b[A\n",
      " 60%|█████▉    | 247545/414113 [00:58<00:38, 4273.37it/s]\u001b[A\n",
      " 60%|█████▉    | 247974/414113 [00:59<00:38, 4277.12it/s]\u001b[A\n",
      " 60%|█████▉    | 248403/414113 [00:59<00:38, 4277.07it/s]\u001b[A\n",
      " 60%|██████    | 248846/414113 [00:59<00:38, 4320.80it/s]\u001b[A\n",
      " 60%|██████    | 249287/414113 [00:59<00:37, 4347.03it/s]\u001b[A\n",
      " 60%|██████    | 249722/414113 [00:59<00:37, 4344.81it/s]\u001b[A\n",
      " 60%|██████    | 250157/414113 [00:59<00:37, 4343.68it/s]\u001b[A\n",
      " 61%|██████    | 250592/414113 [00:59<00:37, 4316.28it/s]\u001b[A\n",
      " 61%|██████    | 251024/414113 [00:59<00:37, 4315.86it/s]\u001b[A\n",
      " 61%|██████    | 251457/414113 [00:59<00:37, 4317.52it/s]\u001b[A\n",
      " 61%|██████    | 251895/414113 [00:59<00:37, 4333.02it/s]\u001b[A\n",
      " 61%|██████    | 252329/414113 [01:00<00:37, 4321.06it/s]\u001b[A\n",
      " 61%|██████    | 252768/414113 [01:00<00:37, 4340.62it/s]\u001b[A\n",
      " 61%|██████    | 253210/414113 [01:00<00:36, 4361.43it/s]\u001b[A\n",
      " 61%|██████▏   | 253647/414113 [01:00<00:36, 4351.65it/s]\u001b[A\n",
      " 61%|██████▏   | 254083/414113 [01:00<00:37, 4308.68it/s]\u001b[A\n",
      " 61%|██████▏   | 254514/414113 [01:00<00:37, 4290.41it/s]\u001b[A\n",
      " 62%|██████▏   | 254951/414113 [01:00<00:36, 4313.66it/s]\u001b[A\n",
      " 62%|██████▏   | 255383/414113 [01:00<00:37, 4276.42it/s]\u001b[A\n",
      " 62%|██████▏   | 255812/414113 [01:00<00:36, 4280.21it/s]\u001b[A\n",
      " 62%|██████▏   | 256243/414113 [01:00<00:36, 4286.83it/s]\u001b[A\n",
      " 62%|██████▏   | 256672/414113 [01:01<00:37, 4194.70it/s]\u001b[A\n",
      " 62%|██████▏   | 257118/414113 [01:01<00:36, 4269.23it/s]\u001b[A\n",
      " 62%|██████▏   | 257561/414113 [01:01<00:36, 4315.30it/s]\u001b[A\n",
      " 62%|██████▏   | 257999/414113 [01:01<00:36, 4332.16it/s]\u001b[A\n",
      " 62%|██████▏   | 258433/414113 [01:01<00:36, 4293.42it/s]\u001b[A\n",
      " 63%|██████▎   | 258863/414113 [01:01<00:36, 4269.27it/s]\u001b[A\n",
      " 63%|██████▎   | 259305/414113 [01:01<00:35, 4313.13it/s]\u001b[A\n",
      " 63%|██████▎   | 259737/414113 [01:01<00:35, 4300.20it/s]\u001b[A\n",
      " 63%|██████▎   | 260168/414113 [01:01<00:35, 4298.18it/s]\u001b[A\n",
      " 63%|██████▎   | 260599/414113 [01:02<00:35, 4301.31it/s]\u001b[A\n",
      " 63%|██████▎   | 261032/414113 [01:02<00:35, 4309.63it/s]\u001b[A\n",
      " 63%|██████▎   | 261477/414113 [01:02<00:35, 4348.65it/s]\u001b[A\n",
      " 63%|██████▎   | 261913/414113 [01:02<00:35, 4335.61it/s]\u001b[A\n",
      " 63%|██████▎   | 262347/414113 [01:02<00:35, 4305.74it/s]\u001b[A\n",
      " 63%|██████▎   | 262778/414113 [01:02<00:35, 4291.51it/s]\u001b[A\n",
      " 64%|██████▎   | 263208/414113 [01:02<00:35, 4249.68it/s]\u001b[A\n",
      " 64%|██████▎   | 263634/414113 [01:02<00:35, 4227.21it/s]\u001b[A\n",
      " 64%|██████▍   | 264057/414113 [01:02<00:35, 4210.45it/s]\u001b[A\n",
      " 64%|██████▍   | 264485/414113 [01:02<00:35, 4228.99it/s]\u001b[A\n",
      " 64%|██████▍   | 264908/414113 [01:03<00:35, 4193.05it/s]\u001b[A\n",
      " 64%|██████▍   | 265330/414113 [01:03<00:35, 4199.77it/s]\u001b[A\n",
      " 64%|██████▍   | 265751/414113 [01:03<00:35, 4198.80it/s]\u001b[A\n",
      " 64%|██████▍   | 266181/414113 [01:03<00:34, 4228.29it/s]\u001b[A\n",
      " 64%|██████▍   | 266604/414113 [01:03<00:35, 4195.48it/s]\u001b[A\n",
      " 64%|██████▍   | 267034/414113 [01:03<00:34, 4225.16it/s]\u001b[A\n",
      " 65%|██████▍   | 267470/414113 [01:03<00:34, 4263.49it/s]\u001b[A\n",
      " 65%|██████▍   | 267898/414113 [01:03<00:34, 4266.00it/s]\u001b[A\n",
      " 65%|██████▍   | 268325/414113 [01:03<00:34, 4260.17it/s]\u001b[A\n",
      " 65%|██████▍   | 268760/414113 [01:03<00:33, 4286.50it/s]\u001b[A\n",
      " 65%|██████▌   | 269191/414113 [01:04<00:33, 4292.10it/s]\u001b[A\n",
      " 65%|██████▌   | 269631/414113 [01:04<00:33, 4322.65it/s]\u001b[A\n",
      " 65%|██████▌   | 270068/414113 [01:04<00:33, 4335.61it/s]\u001b[A\n",
      " 65%|██████▌   | 270504/414113 [01:04<00:33, 4340.48it/s]\u001b[A\n",
      " 65%|██████▌   | 270939/414113 [01:04<00:33, 4320.59it/s]\u001b[A\n",
      " 66%|██████▌   | 271372/414113 [01:04<00:33, 4303.63it/s]\u001b[A\n",
      " 66%|██████▌   | 271805/414113 [01:04<00:33, 4311.06it/s]\u001b[A\n",
      " 66%|██████▌   | 272239/414113 [01:04<00:32, 4318.32it/s]\u001b[A\n",
      " 66%|██████▌   | 272674/414113 [01:04<00:32, 4325.44it/s]\u001b[A\n",
      " 66%|██████▌   | 273116/414113 [01:04<00:32, 4351.21it/s]\u001b[A\n",
      " 66%|██████▌   | 273552/414113 [01:05<00:32, 4293.55it/s]\u001b[A\n",
      " 66%|██████▌   | 273982/414113 [01:05<00:32, 4274.25it/s]\u001b[A\n",
      " 66%|██████▋   | 274410/414113 [01:05<00:32, 4267.02it/s]\u001b[A\n",
      " 66%|██████▋   | 274842/414113 [01:05<00:32, 4279.89it/s]\u001b[A\n",
      " 66%|██████▋   | 275279/414113 [01:05<00:32, 4303.81it/s]\u001b[A\n",
      " 67%|██████▋   | 275725/414113 [01:05<00:31, 4349.28it/s]\u001b[A\n",
      " 67%|██████▋   | 276162/414113 [01:05<00:31, 4353.20it/s]\u001b[A\n",
      " 67%|██████▋   | 276603/414113 [01:05<00:31, 4368.90it/s]\u001b[A\n",
      " 67%|██████▋   | 277040/414113 [01:05<00:31, 4315.94it/s]\u001b[A\n",
      " 67%|██████▋   | 277475/414113 [01:05<00:31, 4324.59it/s]\u001b[A\n",
      " 67%|██████▋   | 277911/414113 [01:06<00:31, 4333.68it/s]\u001b[A\n",
      " 67%|██████▋   | 278345/414113 [01:06<00:31, 4329.01it/s]\u001b[A\n",
      " 67%|██████▋   | 278778/414113 [01:06<00:31, 4287.84it/s]\u001b[A\n",
      " 67%|██████▋   | 279217/414113 [01:06<00:31, 4317.32it/s]\u001b[A\n",
      " 68%|██████▊   | 279649/414113 [01:06<00:31, 4297.94it/s]\u001b[A\n",
      " 68%|██████▊   | 280079/414113 [01:06<00:32, 4093.77it/s]\u001b[A\n",
      " 68%|██████▊   | 280501/414113 [01:06<00:32, 4130.18it/s]\u001b[A\n",
      " 68%|██████▊   | 280927/414113 [01:06<00:31, 4167.36it/s]\u001b[A\n",
      " 68%|██████▊   | 281345/414113 [01:06<00:31, 4170.64it/s]\u001b[A\n",
      " 68%|██████▊   | 281767/414113 [01:06<00:31, 4184.65it/s]\u001b[A\n",
      " 68%|██████▊   | 282205/414113 [01:07<00:31, 4239.04it/s]\u001b[A\n",
      " 68%|██████▊   | 282631/414113 [01:07<00:30, 4242.41it/s]\u001b[A\n",
      " 68%|██████▊   | 283061/414113 [01:07<00:30, 4256.99it/s]\u001b[A\n",
      " 68%|██████▊   | 283487/414113 [01:07<00:30, 4255.35it/s]\u001b[A\n",
      " 69%|██████▊   | 283924/414113 [01:07<00:30, 4287.90it/s]\u001b[A\n",
      " 69%|██████▊   | 284355/414113 [01:07<00:30, 4291.90it/s]\u001b[A\n",
      " 69%|██████▉   | 284787/414113 [01:07<00:30, 4298.53it/s]\u001b[A\n",
      " 69%|██████▉   | 285217/414113 [01:07<00:30, 4286.41it/s]\u001b[A\n",
      " 69%|██████▉   | 285649/414113 [01:07<00:29, 4294.44it/s]\u001b[A\n",
      " 69%|██████▉   | 286083/414113 [01:07<00:29, 4304.87it/s]\u001b[A\n",
      " 69%|██████▉   | 286515/414113 [01:08<00:29, 4307.40it/s]\u001b[A\n",
      " 69%|██████▉   | 286946/414113 [01:08<00:29, 4286.85it/s]\u001b[A\n",
      " 69%|██████▉   | 287375/414113 [01:08<00:29, 4273.56it/s]\u001b[A\n",
      " 69%|██████▉   | 287807/414113 [01:08<00:29, 4287.35it/s]\u001b[A\n",
      " 70%|██████▉   | 288244/414113 [01:08<00:29, 4311.19it/s]\u001b[A\n",
      " 70%|██████▉   | 288680/414113 [01:08<00:29, 4325.00it/s]\u001b[A\n",
      " 70%|██████▉   | 289113/414113 [01:08<00:29, 4287.99it/s]\u001b[A\n",
      " 70%|██████▉   | 289547/414113 [01:08<00:28, 4300.32it/s]\u001b[A\n",
      " 70%|███████   | 289982/414113 [01:08<00:28, 4313.98it/s]\u001b[A\n",
      " 70%|███████   | 290418/414113 [01:08<00:28, 4326.51it/s]\u001b[A\n",
      " 70%|███████   | 290859/414113 [01:09<00:28, 4350.08it/s]\u001b[A\n",
      " 70%|███████   | 291295/414113 [01:09<00:28, 4342.20it/s]\u001b[A\n",
      " 70%|███████   | 291730/414113 [01:09<00:28, 4309.52it/s]\u001b[A\n",
      " 71%|███████   | 292175/414113 [01:09<00:28, 4349.26it/s]\u001b[A\n",
      " 71%|███████   | 292623/414113 [01:09<00:27, 4385.54it/s]\u001b[A\n",
      " 71%|███████   | 293073/414113 [01:09<00:27, 4416.65it/s]\u001b[A\n",
      " 71%|███████   | 293519/414113 [01:09<00:27, 4427.00it/s]\u001b[A\n",
      " 71%|███████   | 293962/414113 [01:09<00:27, 4372.43it/s]\u001b[A\n",
      " 71%|███████   | 294400/414113 [01:09<00:27, 4367.94it/s]\u001b[A\n",
      " 71%|███████   | 294837/414113 [01:09<00:27, 4361.52it/s]\u001b[A\n",
      " 71%|███████▏  | 295276/414113 [01:10<00:27, 4369.33it/s]\u001b[A\n",
      " 71%|███████▏  | 295714/414113 [01:10<00:27, 4345.80it/s]\u001b[A\n",
      " 72%|███████▏  | 296149/414113 [01:10<00:27, 4308.39it/s]\u001b[A\n",
      " 72%|███████▏  | 296580/414113 [01:10<00:27, 4296.09it/s]\u001b[A\n",
      " 72%|███████▏  | 297011/414113 [01:10<00:27, 4300.05it/s]\u001b[A\n",
      " 72%|███████▏  | 297442/414113 [01:10<00:27, 4265.14it/s]\u001b[A\n",
      " 72%|███████▏  | 297869/414113 [01:10<00:27, 4206.29it/s]\u001b[A\n",
      " 72%|███████▏  | 298290/414113 [01:10<00:27, 4183.36it/s]\u001b[A\n",
      " 72%|███████▏  | 298716/414113 [01:10<00:27, 4205.64it/s]\u001b[A\n",
      " 72%|███████▏  | 299148/414113 [01:11<00:27, 4237.19it/s]\u001b[A\n",
      " 72%|███████▏  | 299583/414113 [01:11<00:26, 4268.55it/s]\u001b[A\n",
      " 72%|███████▏  | 300012/414113 [01:11<00:26, 4274.31it/s]\u001b[A\n",
      " 73%|███████▎  | 300440/414113 [01:11<00:47, 2374.00it/s]\u001b[A\n",
      " 73%|███████▎  | 300855/414113 [01:11<00:41, 2723.12it/s]\u001b[A\n",
      " 73%|███████▎  | 301276/414113 [01:11<00:37, 3044.57it/s]\u001b[A\n",
      " 73%|███████▎  | 301703/414113 [01:11<00:33, 3331.20it/s]\u001b[A\n",
      " 73%|███████▎  | 302155/414113 [01:11<00:30, 3615.57it/s]\u001b[A\n",
      " 73%|███████▎  | 302579/414113 [01:12<00:29, 3782.51it/s]\u001b[A\n",
      " 73%|███████▎  | 303010/414113 [01:12<00:28, 3926.56it/s]\u001b[A\n",
      " 73%|███████▎  | 303444/414113 [01:12<00:27, 4041.13it/s]\u001b[A\n",
      " 73%|███████▎  | 303875/414113 [01:12<00:26, 4117.55it/s]\u001b[A\n",
      " 73%|███████▎  | 304308/414113 [01:12<00:26, 4177.24it/s]\u001b[A\n",
      " 74%|███████▎  | 304736/414113 [01:12<00:26, 4184.47it/s]\u001b[A\n",
      " 74%|███████▎  | 305162/414113 [01:12<00:26, 4158.90it/s]\u001b[A\n",
      " 74%|███████▍  | 305583/414113 [01:12<00:26, 4147.29it/s]\u001b[A\n",
      " 74%|███████▍  | 306015/414113 [01:12<00:25, 4196.23it/s]\u001b[A\n",
      " 74%|███████▍  | 306451/414113 [01:12<00:25, 4241.30it/s]\u001b[A\n",
      " 74%|███████▍  | 306878/414113 [01:13<00:25, 4226.50it/s]\u001b[A\n",
      " 74%|███████▍  | 307306/414113 [01:13<00:25, 4240.42it/s]\u001b[A\n",
      " 74%|███████▍  | 307741/414113 [01:13<00:24, 4272.47it/s]\u001b[A\n",
      " 74%|███████▍  | 308188/414113 [01:13<00:24, 4329.10it/s]\u001b[A\n",
      " 75%|███████▍  | 308635/414113 [01:13<00:24, 4368.34it/s]\u001b[A\n",
      " 75%|███████▍  | 309073/414113 [01:13<00:24, 4212.64it/s]\u001b[A\n",
      " 75%|███████▍  | 309504/414113 [01:13<00:24, 4240.30it/s]\u001b[A\n",
      " 75%|███████▍  | 309931/414113 [01:13<00:24, 4248.47it/s]\u001b[A\n",
      " 75%|███████▍  | 310367/414113 [01:13<00:24, 4279.29it/s]\u001b[A\n",
      " 75%|███████▌  | 310797/414113 [01:13<00:24, 4284.61it/s]\u001b[A\n",
      " 75%|███████▌  | 311226/414113 [01:14<00:24, 4272.73it/s]\u001b[A\n",
      " 75%|███████▌  | 311654/414113 [01:14<00:24, 4251.01it/s]\u001b[A\n",
      " 75%|███████▌  | 312081/414113 [01:14<00:23, 4254.63it/s]\u001b[A\n",
      " 75%|███████▌  | 312516/414113 [01:14<00:23, 4281.20it/s]\u001b[A\n",
      " 76%|███████▌  | 312945/414113 [01:14<00:23, 4276.08it/s]\u001b[A\n",
      " 76%|███████▌  | 313373/414113 [01:14<00:23, 4254.02it/s]\u001b[A\n",
      " 76%|███████▌  | 313799/414113 [01:14<00:24, 4048.07it/s]\u001b[A\n",
      " 76%|███████▌  | 314225/414113 [01:14<00:24, 4108.84it/s]\u001b[A\n",
      " 76%|███████▌  | 314643/414113 [01:14<00:24, 4128.80it/s]\u001b[A\n",
      " 76%|███████▌  | 315065/414113 [01:15<00:23, 4154.10it/s]\u001b[A\n",
      " 76%|███████▌  | 315491/414113 [01:15<00:23, 4181.97it/s]\u001b[A\n",
      " 76%|███████▋  | 315910/414113 [01:15<00:23, 4180.65it/s]\u001b[A\n",
      " 76%|███████▋  | 316352/414113 [01:15<00:23, 4248.66it/s]\u001b[A\n",
      " 77%|███████▋  | 316801/414113 [01:15<00:22, 4315.94it/s]\u001b[A\n",
      " 77%|███████▋  | 317234/414113 [01:15<00:22, 4312.07it/s]\u001b[A\n",
      " 77%|███████▋  | 317667/414113 [01:15<00:22, 4317.42it/s]\u001b[A\n",
      " 77%|███████▋  | 318100/414113 [01:15<00:22, 4273.36it/s]\u001b[A\n",
      " 77%|███████▋  | 318543/414113 [01:15<00:22, 4316.80it/s]\u001b[A\n",
      " 77%|███████▋  | 318976/414113 [01:15<00:22, 4302.42it/s]\u001b[A\n",
      " 77%|███████▋  | 319407/414113 [01:16<00:22, 4275.21it/s]\u001b[A\n",
      " 77%|███████▋  | 319839/414113 [01:16<00:21, 4285.51it/s]\u001b[A\n",
      " 77%|███████▋  | 320273/414113 [01:16<00:21, 4301.70it/s]\u001b[A\n",
      " 77%|███████▋  | 320713/414113 [01:16<00:21, 4328.54it/s]\u001b[A\n",
      " 78%|███████▊  | 321147/414113 [01:16<00:21, 4329.58it/s]\u001b[A\n",
      " 78%|███████▊  | 321581/414113 [01:16<00:21, 4298.03it/s]\u001b[A\n",
      " 78%|███████▊  | 322011/414113 [01:16<00:24, 3702.91it/s]\u001b[A\n",
      " 78%|███████▊  | 322442/414113 [01:16<00:23, 3865.00it/s]\u001b[A\n",
      " 78%|███████▊  | 322863/414113 [01:16<00:23, 3959.96it/s]\u001b[A\n",
      " 78%|███████▊  | 323295/414113 [01:16<00:22, 4060.95it/s]\u001b[A\n",
      " 78%|███████▊  | 323714/414113 [01:17<00:22, 4098.49it/s]\u001b[A\n",
      " 78%|███████▊  | 324137/414113 [01:17<00:21, 4135.79it/s]\u001b[A\n",
      " 78%|███████▊  | 324575/414113 [01:17<00:21, 4205.68it/s]\u001b[A\n",
      " 78%|███████▊  | 325018/414113 [01:17<00:20, 4268.00it/s]\u001b[A\n",
      " 79%|███████▊  | 325447/414113 [01:17<00:20, 4232.93it/s]\u001b[A\n",
      " 79%|███████▊  | 325879/414113 [01:17<00:20, 4256.01it/s]\u001b[A\n",
      " 79%|███████▉  | 326321/414113 [01:17<00:20, 4302.45it/s]\u001b[A\n",
      " 79%|███████▉  | 326755/414113 [01:17<00:20, 4313.23it/s]\u001b[A\n",
      " 79%|███████▉  | 327187/414113 [01:17<00:20, 4288.90it/s]\u001b[A\n",
      " 79%|███████▉  | 327617/414113 [01:17<00:20, 4273.12it/s]\u001b[A\n",
      " 79%|███████▉  | 328045/414113 [01:18<00:20, 4225.78it/s]\u001b[A\n",
      " 79%|███████▉  | 328468/414113 [01:18<00:20, 4216.66it/s]\u001b[A\n",
      " 79%|███████▉  | 328890/414113 [01:18<00:20, 4192.84it/s]\u001b[A\n",
      " 80%|███████▉  | 329313/414113 [01:18<00:20, 4202.56it/s]\u001b[A\n",
      " 80%|███████▉  | 329734/414113 [01:18<00:20, 4161.53it/s]\u001b[A\n",
      " 80%|███████▉  | 330151/414113 [01:18<00:20, 4159.01it/s]\u001b[A\n",
      " 80%|███████▉  | 330570/414113 [01:18<00:20, 4167.61it/s]\u001b[A\n",
      " 80%|███████▉  | 330987/414113 [01:18<00:20, 4151.81it/s]\u001b[A\n",
      " 80%|████████  | 331403/414113 [01:18<00:20, 4130.57it/s]\u001b[A\n",
      " 80%|████████  | 331824/414113 [01:19<00:19, 4153.92it/s]\u001b[A\n",
      " 80%|████████  | 332248/414113 [01:19<00:19, 4178.63it/s]\u001b[A\n",
      " 80%|████████  | 332674/414113 [01:19<00:19, 4200.52it/s]\u001b[A\n",
      " 80%|████████  | 333109/414113 [01:19<00:19, 4242.67it/s]\u001b[A\n",
      " 81%|████████  | 333544/414113 [01:19<00:18, 4273.58it/s]\u001b[A\n",
      " 81%|████████  | 333977/414113 [01:19<00:18, 4289.68it/s]\u001b[A\n",
      " 81%|████████  | 334407/414113 [01:19<00:19, 4171.56it/s]\u001b[A\n",
      " 81%|████████  | 334848/414113 [01:19<00:18, 4238.07it/s]\u001b[A\n",
      " 81%|████████  | 335275/414113 [01:19<00:18, 4247.29it/s]\u001b[A\n",
      " 81%|████████  | 335701/414113 [01:19<00:18, 4198.61it/s]\u001b[A\n",
      " 81%|████████  | 336122/414113 [01:20<00:18, 4197.37it/s]\u001b[A\n",
      " 81%|████████▏ | 336543/414113 [01:20<00:18, 4189.95it/s]\u001b[A\n",
      " 81%|████████▏ | 336963/414113 [01:20<00:18, 4151.91it/s]\u001b[A\n",
      " 81%|████████▏ | 337379/414113 [01:20<00:18, 4131.35it/s]\u001b[A\n",
      " 82%|████████▏ | 337808/414113 [01:20<00:18, 4175.84it/s]\u001b[A\n",
      " 82%|████████▏ | 338226/414113 [01:20<00:18, 4120.29it/s]\u001b[A\n",
      " 82%|████████▏ | 338647/414113 [01:20<00:18, 4145.31it/s]\u001b[A\n",
      " 82%|████████▏ | 339062/414113 [01:20<00:18, 4137.97it/s]\u001b[A\n",
      " 82%|████████▏ | 339482/414113 [01:20<00:17, 4156.38it/s]\u001b[A\n",
      " 82%|████████▏ | 339898/414113 [01:20<00:17, 4150.87it/s]\u001b[A\n",
      " 82%|████████▏ | 340328/414113 [01:21<00:17, 4191.40it/s]\u001b[A\n",
      " 82%|████████▏ | 340748/414113 [01:21<00:17, 4164.27it/s]\u001b[A\n",
      " 82%|████████▏ | 341173/414113 [01:21<00:17, 4189.06it/s]\u001b[A\n",
      " 82%|████████▏ | 341606/414113 [01:21<00:17, 4229.16it/s]\u001b[A\n",
      " 83%|████████▎ | 342030/414113 [01:21<00:17, 4199.76it/s]\u001b[A\n",
      " 83%|████████▎ | 342451/414113 [01:21<00:17, 4198.67it/s]\u001b[A\n",
      " 83%|████████▎ | 342876/414113 [01:21<00:16, 4213.88it/s]\u001b[A\n",
      " 83%|████████▎ | 343300/414113 [01:21<00:16, 4220.90it/s]\u001b[A\n",
      " 83%|████████▎ | 343723/414113 [01:21<00:16, 4209.55it/s]\u001b[A\n",
      " 83%|████████▎ | 344149/414113 [01:21<00:16, 4222.85it/s]\u001b[A\n",
      " 83%|████████▎ | 344572/414113 [01:22<00:16, 4200.12it/s]\u001b[A\n",
      " 83%|████████▎ | 344993/414113 [01:22<00:16, 4187.04it/s]\u001b[A\n",
      " 83%|████████▎ | 345412/414113 [01:22<00:16, 4178.82it/s]\u001b[A\n",
      " 84%|████████▎ | 345830/414113 [01:22<00:16, 4173.12it/s]\u001b[A\n",
      " 84%|████████▎ | 346266/414113 [01:22<00:16, 4225.49it/s]\u001b[A\n",
      " 84%|████████▎ | 346689/414113 [01:22<00:16, 4188.30it/s]\u001b[A\n",
      " 84%|████████▍ | 347123/414113 [01:22<00:15, 4230.94it/s]\u001b[A\n",
      " 84%|████████▍ | 347547/414113 [01:22<00:15, 4200.05it/s]\u001b[A\n",
      " 84%|████████▍ | 347968/414113 [01:22<00:15, 4185.90it/s]\u001b[A\n",
      " 84%|████████▍ | 348387/414113 [01:22<00:15, 4158.29it/s]\u001b[A\n",
      " 84%|████████▍ | 348804/414113 [01:23<00:15, 4161.46it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 349231/414113 [01:23<00:15, 4193.12it/s]\u001b[A\n",
      " 84%|████████▍ | 349658/414113 [01:23<00:15, 4213.36it/s]\u001b[A\n",
      " 85%|████████▍ | 350086/414113 [01:23<00:15, 4233.13it/s]\u001b[A\n",
      " 85%|████████▍ | 350514/414113 [01:23<00:14, 4245.30it/s]\u001b[A\n",
      " 85%|████████▍ | 350944/414113 [01:23<00:14, 4261.26it/s]\u001b[A\n",
      " 85%|████████▍ | 351386/414113 [01:23<00:14, 4304.56it/s]\u001b[A\n",
      " 85%|████████▍ | 351817/414113 [01:23<00:14, 4262.96it/s]\u001b[A\n",
      " 85%|████████▌ | 352249/414113 [01:23<00:14, 4279.64it/s]\u001b[A\n",
      " 85%|████████▌ | 352678/414113 [01:23<00:14, 4279.14it/s]\u001b[A\n",
      " 85%|████████▌ | 353107/414113 [01:24<00:14, 4264.31it/s]\u001b[A\n",
      " 85%|████████▌ | 353541/414113 [01:24<00:14, 4285.67it/s]\u001b[A\n",
      " 85%|████████▌ | 353970/414113 [01:24<00:14, 4270.10it/s]\u001b[A\n",
      " 86%|████████▌ | 354398/414113 [01:24<00:13, 4269.05it/s]\u001b[A\n",
      " 86%|████████▌ | 354826/414113 [01:24<00:13, 4270.31it/s]\u001b[A\n",
      " 86%|████████▌ | 355254/414113 [01:24<00:13, 4257.14it/s]\u001b[A\n",
      " 86%|████████▌ | 355680/414113 [01:24<00:13, 4254.66it/s]\u001b[A\n",
      " 86%|████████▌ | 356106/414113 [01:24<00:13, 4239.44it/s]\u001b[A\n",
      " 86%|████████▌ | 356530/414113 [01:24<00:13, 4238.17it/s]\u001b[A\n",
      " 86%|████████▌ | 356954/414113 [01:24<00:13, 4219.08it/s]\u001b[A\n",
      " 86%|████████▋ | 357376/414113 [01:25<00:13, 4195.93it/s]\u001b[A\n",
      " 86%|████████▋ | 357813/414113 [01:25<00:13, 4246.34it/s]\u001b[A\n",
      " 87%|████████▋ | 358238/414113 [01:25<00:13, 4212.30it/s]\u001b[A\n",
      " 87%|████████▋ | 358666/414113 [01:25<00:13, 4225.05it/s]\u001b[A\n",
      " 87%|████████▋ | 359089/414113 [01:25<00:13, 4196.77it/s]\u001b[A\n",
      " 87%|████████▋ | 359524/414113 [01:25<00:12, 4239.37it/s]\u001b[A\n",
      " 87%|████████▋ | 359963/414113 [01:25<00:12, 4280.49it/s]\u001b[A\n",
      " 87%|████████▋ | 360392/414113 [01:25<00:12, 4235.15it/s]\u001b[A\n",
      " 87%|████████▋ | 360816/414113 [01:25<00:12, 4214.95it/s]\u001b[A\n",
      " 87%|████████▋ | 361242/414113 [01:25<00:12, 4226.50it/s]\u001b[A\n",
      " 87%|████████▋ | 361665/414113 [01:26<00:12, 4210.28it/s]\u001b[A\n",
      " 87%|████████▋ | 362099/414113 [01:26<00:12, 4248.17it/s]\u001b[A\n",
      " 88%|████████▊ | 362524/414113 [01:26<00:12, 4172.79it/s]\u001b[A\n",
      " 88%|████████▊ | 362942/414113 [01:26<00:13, 3865.01it/s]\u001b[A\n",
      " 88%|████████▊ | 363368/414113 [01:26<00:12, 3975.14it/s]\u001b[A\n",
      " 88%|████████▊ | 363791/414113 [01:26<00:12, 4048.15it/s]\u001b[A\n",
      " 88%|████████▊ | 364205/414113 [01:26<00:12, 4074.29it/s]\u001b[A\n",
      " 88%|████████▊ | 364621/414113 [01:26<00:12, 4097.65it/s]\u001b[A\n",
      " 88%|████████▊ | 365044/414113 [01:26<00:11, 4134.40it/s]\u001b[A\n",
      " 88%|████████▊ | 365482/414113 [01:27<00:11, 4204.45it/s]\u001b[A\n",
      " 88%|████████▊ | 365918/414113 [01:27<00:11, 4246.79it/s]\u001b[A\n",
      " 88%|████████▊ | 366344/414113 [01:27<00:11, 4208.60it/s]\u001b[A\n",
      " 89%|████████▊ | 366766/414113 [01:27<00:11, 4210.30it/s]\u001b[A\n",
      " 89%|████████▊ | 367188/414113 [01:27<00:11, 4183.49it/s]\u001b[A\n",
      " 89%|████████▉ | 367621/414113 [01:27<00:11, 4224.99it/s]\u001b[A\n",
      " 89%|████████▉ | 368054/414113 [01:27<00:10, 4253.32it/s]\u001b[A\n",
      " 89%|████████▉ | 368480/414113 [01:27<00:10, 4241.29it/s]\u001b[A\n",
      " 89%|████████▉ | 368905/414113 [01:27<00:10, 4242.19it/s]\u001b[A\n",
      " 89%|████████▉ | 369330/414113 [01:27<00:10, 4230.39it/s]\u001b[A\n",
      " 89%|████████▉ | 369754/414113 [01:28<00:10, 4196.20it/s]\u001b[A\n",
      " 89%|████████▉ | 370174/414113 [01:28<00:10, 4183.26it/s]\u001b[A\n",
      " 89%|████████▉ | 370593/414113 [01:28<00:10, 4153.66it/s]\u001b[A\n",
      " 90%|████████▉ | 371009/414113 [01:28<00:10, 4147.43it/s]\u001b[A\n",
      " 90%|████████▉ | 371433/414113 [01:28<00:10, 4172.59it/s]\u001b[A\n",
      " 90%|████████▉ | 371863/414113 [01:28<00:10, 4209.66it/s]\u001b[A\n",
      " 90%|████████▉ | 372289/414113 [01:28<00:09, 4222.78it/s]\u001b[A\n",
      " 90%|█████████ | 372715/414113 [01:28<00:09, 4231.67it/s]\u001b[A\n",
      " 90%|█████████ | 373147/414113 [01:28<00:09, 4257.00it/s]\u001b[A\n",
      " 90%|█████████ | 373574/414113 [01:28<00:09, 4258.88it/s]\u001b[A\n",
      " 90%|█████████ | 374003/414113 [01:29<00:09, 4267.99it/s]\u001b[A\n",
      " 90%|█████████ | 374430/414113 [01:29<00:09, 4235.85it/s]\u001b[A\n",
      " 91%|█████████ | 374854/414113 [01:29<00:09, 4230.24it/s]\u001b[A\n",
      " 91%|█████████ | 375289/414113 [01:29<00:09, 4264.66it/s]\u001b[A\n",
      " 91%|█████████ | 375717/414113 [01:29<00:08, 4269.11it/s]\u001b[A\n",
      " 91%|█████████ | 376164/414113 [01:29<00:08, 4325.52it/s]\u001b[A\n",
      " 91%|█████████ | 376597/414113 [01:29<00:08, 4309.30it/s]\u001b[A\n",
      " 91%|█████████ | 377029/414113 [01:29<00:08, 4300.65it/s]\u001b[A\n",
      " 91%|█████████ | 377460/414113 [01:29<00:08, 4229.95it/s]\u001b[A\n",
      " 91%|█████████▏| 377898/414113 [01:29<00:08, 4271.39it/s]\u001b[A\n",
      " 91%|█████████▏| 378343/414113 [01:30<00:08, 4322.62it/s]\u001b[A\n",
      " 91%|█████████▏| 378776/414113 [01:30<00:08, 4299.27it/s]\u001b[A\n",
      " 92%|█████████▏| 379207/414113 [01:30<00:08, 4075.21it/s]\u001b[A\n",
      " 92%|█████████▏| 379635/414113 [01:30<00:08, 4132.69it/s]\u001b[A\n",
      " 92%|█████████▏| 380076/414113 [01:30<00:08, 4210.57it/s]\u001b[A\n",
      " 92%|█████████▏| 380512/414113 [01:30<00:07, 4252.41it/s]\u001b[A\n",
      " 92%|█████████▏| 380939/414113 [01:30<00:07, 4245.11it/s]\u001b[A\n",
      " 92%|█████████▏| 381369/414113 [01:30<00:07, 4261.08it/s]\u001b[A\n",
      " 92%|█████████▏| 381796/414113 [01:30<00:07, 4244.74it/s]\u001b[A\n",
      " 92%|█████████▏| 382234/414113 [01:30<00:07, 4283.31it/s]\u001b[A\n",
      " 92%|█████████▏| 382663/414113 [01:31<00:07, 4268.24it/s]\u001b[A\n",
      " 93%|█████████▎| 383101/414113 [01:31<00:07, 4299.54it/s]\u001b[A\n",
      " 93%|█████████▎| 383536/414113 [01:31<00:07, 4313.52it/s]\u001b[A\n",
      " 93%|█████████▎| 383968/414113 [01:31<00:07, 4298.75it/s]\u001b[A\n",
      " 93%|█████████▎| 384399/414113 [01:31<00:06, 4298.12it/s]\u001b[A\n",
      " 93%|█████████▎| 384834/414113 [01:31<00:06, 4312.39it/s]\u001b[A\n",
      " 93%|█████████▎| 385266/414113 [01:31<00:06, 4281.52it/s]\u001b[A\n",
      " 93%|█████████▎| 385700/414113 [01:31<00:06, 4297.72it/s]\u001b[A\n",
      " 93%|█████████▎| 386130/414113 [01:31<00:06, 4271.32it/s]\u001b[A\n",
      " 93%|█████████▎| 386558/414113 [01:31<00:06, 4267.53it/s]\u001b[A\n",
      " 93%|█████████▎| 386985/414113 [01:32<00:06, 4265.94it/s]\u001b[A\n",
      " 94%|█████████▎| 387412/414113 [01:32<00:06, 4220.85it/s]\u001b[A\n",
      " 94%|█████████▎| 387836/414113 [01:32<00:06, 4223.78it/s]\u001b[A\n",
      " 94%|█████████▍| 388264/414113 [01:32<00:06, 4238.88it/s]\u001b[A\n",
      " 94%|█████████▍| 388696/414113 [01:32<00:05, 4262.01it/s]\u001b[A\n",
      " 94%|█████████▍| 389135/414113 [01:32<00:05, 4297.01it/s]\u001b[A\n",
      " 94%|█████████▍| 389565/414113 [01:32<00:05, 4228.84it/s]\u001b[A\n",
      " 94%|█████████▍| 389989/414113 [01:32<00:05, 4063.47it/s]\u001b[A\n",
      " 94%|█████████▍| 390428/414113 [01:32<00:05, 4154.21it/s]\u001b[A\n",
      " 94%|█████████▍| 390846/414113 [01:33<00:05, 4139.18it/s]\u001b[A\n",
      " 94%|█████████▍| 391262/414113 [01:33<00:05, 4118.55it/s]\u001b[A\n",
      " 95%|█████████▍| 391695/414113 [01:33<00:05, 4177.24it/s]\u001b[A\n",
      " 95%|█████████▍| 392117/414113 [01:33<00:05, 4189.30it/s]\u001b[A\n",
      " 95%|█████████▍| 392556/414113 [01:33<00:05, 4247.41it/s]\u001b[A\n",
      " 95%|█████████▍| 392984/414113 [01:33<00:04, 4255.62it/s]\u001b[A\n",
      " 95%|█████████▌| 393410/414113 [01:33<00:04, 4237.13it/s]\u001b[A\n",
      " 95%|█████████▌| 393842/414113 [01:33<00:04, 4260.02it/s]\u001b[A\n",
      " 95%|█████████▌| 394269/414113 [01:33<00:04, 4261.15it/s]\u001b[A\n",
      " 95%|█████████▌| 394697/414113 [01:33<00:04, 4265.65it/s]\u001b[A\n",
      " 95%|█████████▌| 395133/414113 [01:34<00:04, 4292.51it/s]\u001b[A\n",
      " 96%|█████████▌| 395563/414113 [01:34<00:04, 4280.82it/s]\u001b[A\n",
      " 96%|█████████▌| 395995/414113 [01:34<00:04, 4290.26it/s]\u001b[A\n",
      " 96%|█████████▌| 396429/414113 [01:34<00:04, 4302.64it/s]\u001b[A\n",
      " 96%|█████████▌| 396871/414113 [01:34<00:03, 4336.13it/s]\u001b[A\n",
      " 96%|█████████▌| 397305/414113 [01:34<00:03, 4315.68it/s]\u001b[A\n",
      " 96%|█████████▌| 397737/414113 [01:34<00:03, 4286.58it/s]\u001b[A\n",
      " 96%|█████████▌| 398166/414113 [01:34<00:03, 4213.42it/s]\u001b[A\n",
      " 96%|█████████▋| 398594/414113 [01:34<00:03, 4231.98it/s]\u001b[A\n",
      " 96%|█████████▋| 399018/414113 [01:34<00:03, 4228.84it/s]\u001b[A\n",
      " 96%|█████████▋| 399442/414113 [01:35<00:03, 4171.53it/s]\u001b[A\n",
      " 97%|█████████▋| 399860/414113 [01:35<00:03, 4157.71it/s]\u001b[A\n",
      " 97%|█████████▋| 400276/414113 [01:35<00:03, 4151.50it/s]\u001b[A\n",
      " 97%|█████████▋| 400706/414113 [01:35<00:03, 4194.03it/s]\u001b[A\n",
      " 97%|█████████▋| 401126/414113 [01:35<00:03, 4133.23it/s]\u001b[A\n",
      " 97%|█████████▋| 401562/414113 [01:35<00:02, 4198.21it/s]\u001b[A\n",
      " 97%|█████████▋| 401983/414113 [01:35<00:02, 4194.45it/s]\u001b[A\n",
      " 97%|█████████▋| 402415/414113 [01:35<00:02, 4231.10it/s]\u001b[A\n",
      " 97%|█████████▋| 402853/414113 [01:35<00:02, 4272.32it/s]\u001b[A\n",
      " 97%|█████████▋| 403289/414113 [01:35<00:02, 4298.15it/s]\u001b[A\n",
      " 97%|█████████▋| 403720/414113 [01:36<00:02, 4274.99it/s]\u001b[A\n",
      " 98%|█████████▊| 404158/414113 [01:36<00:02, 4305.19it/s]\u001b[A\n",
      " 98%|█████████▊| 404589/414113 [01:36<00:02, 4285.23it/s]\u001b[A\n",
      " 98%|█████████▊| 405025/414113 [01:36<00:02, 4304.59it/s]\u001b[A\n",
      " 98%|█████████▊| 405456/414113 [01:36<00:02, 4304.04it/s]\u001b[A\n",
      " 98%|█████████▊| 405887/414113 [01:36<00:01, 4276.79it/s]\u001b[A\n",
      " 98%|█████████▊| 406315/414113 [01:36<00:01, 4222.83it/s]\u001b[A\n",
      " 98%|█████████▊| 406742/414113 [01:36<00:01, 4233.99it/s]\u001b[A\n",
      " 98%|█████████▊| 407166/414113 [01:36<00:01, 4176.45it/s]\u001b[A\n",
      " 98%|█████████▊| 407588/414113 [01:36<00:01, 4188.97it/s]\u001b[A\n",
      " 99%|█████████▊| 408012/414113 [01:37<00:01, 4200.64it/s]\u001b[A\n",
      " 99%|█████████▊| 408447/414113 [01:37<00:01, 4242.24it/s]\u001b[A\n",
      " 99%|█████████▊| 408873/414113 [01:37<00:01, 4247.51it/s]\u001b[A\n",
      " 99%|█████████▉| 409308/414113 [01:37<00:01, 4272.68it/s]\u001b[A\n",
      " 99%|█████████▉| 409737/414113 [01:37<00:01, 4277.47it/s]\u001b[A\n",
      " 99%|█████████▉| 410165/414113 [01:37<00:00, 4266.83it/s]\u001b[A\n",
      " 99%|█████████▉| 410592/414113 [01:37<00:00, 4259.93it/s]\u001b[A\n",
      " 99%|█████████▉| 411022/414113 [01:37<00:00, 4270.80it/s]\u001b[A\n",
      " 99%|█████████▉| 411450/414113 [01:37<00:00, 4262.79it/s]\u001b[A\n",
      " 99%|█████████▉| 411877/414113 [01:37<00:00, 4262.86it/s]\u001b[A\n",
      "100%|█████████▉| 412304/414113 [01:38<00:00, 4235.88it/s]\u001b[A\n",
      "100%|█████████▉| 412729/414113 [01:38<00:00, 4239.17it/s]\u001b[A\n",
      "100%|█████████▉| 413176/414113 [01:38<00:00, 4305.21it/s]\u001b[A\n",
      "100%|█████████▉| 413611/414113 [01:38<00:00, 4317.36it/s]\u001b[A\n",
      "100%|█████████▉| 414043/414113 [01:38<00:00, 4288.30it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:38<00:00, 4205.46it/s]\u001b[ADownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "\n",
      "  0%|          | 0/102502400 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 49152/102502400 [00:00<03:38, 469256.44it/s]\u001b[A\n",
      "  1%|          | 901120/102502400 [00:00<02:35, 654872.88it/s]\u001b[A\n",
      "  4%|▍         | 4382720/102502400 [00:00<01:45, 927508.50it/s]\u001b[A\n",
      " 13%|█▎        | 13721600/102502400 [00:00<01:07, 1319389.78it/s]\u001b[A\n",
      " 22%|██▏       | 23044096/102502400 [00:00<00:42, 1873474.99it/s]\u001b[A\n",
      " 33%|███▎      | 33538048/102502400 [00:00<00:25, 2656065.24it/s]\u001b[A\n",
      " 42%|████▏     | 42565632/102502400 [00:00<00:15, 3747123.32it/s]\u001b[A\n",
      " 51%|█████     | 51863552/102502400 [00:00<00:09, 5262136.45it/s]\u001b[A\n",
      " 59%|█████▉    | 60973056/102502400 [00:00<00:05, 7335444.78it/s]\u001b[A\n",
      " 69%|██████▊   | 70295552/102502400 [00:01<00:03, 10137192.84it/s]\u001b[A\n",
      " 77%|███████▋  | 78954496/102502400 [00:01<00:01, 13623159.62it/s]\u001b[A\n",
      " 86%|████████▌ | 88023040/102502400 [00:01<00:00, 18284187.48it/s]\u001b[A\n",
      " 94%|█████████▍| 96436224/102502400 [00:01<00:00, 23689439.42it/s]\u001b[A\n",
      "100%|██████████| 102502400/102502400 [00:01<00:00, 72451653.20it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 32          # batch size\n",
    "vocab_threshold = 4        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params=params, lr = 0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/12942], Loss: 3.8702, Perplexity: 47.95284\n",
      "Epoch [1/3], Step [200/12942], Loss: 3.4745, Perplexity: 32.28338\n",
      "Epoch [1/3], Step [300/12942], Loss: 3.4765, Perplexity: 32.3474\n",
      "Epoch [1/3], Step [400/12942], Loss: 3.0019, Perplexity: 20.1232\n",
      "Epoch [1/3], Step [500/12942], Loss: 3.1203, Perplexity: 22.6521\n",
      "Epoch [1/3], Step [600/12942], Loss: 2.9334, Perplexity: 18.7905\n",
      "Epoch [1/3], Step [700/12942], Loss: 3.0991, Perplexity: 22.1772\n",
      "Epoch [1/3], Step [800/12942], Loss: 3.5576, Perplexity: 35.0805\n",
      "Epoch [1/3], Step [900/12942], Loss: 2.6942, Perplexity: 14.7938\n",
      "Epoch [1/3], Step [1000/12942], Loss: 2.8303, Perplexity: 16.9497\n",
      "Epoch [1/3], Step [1100/12942], Loss: 2.6748, Perplexity: 14.5096\n",
      "Epoch [1/3], Step [1200/12942], Loss: 3.1348, Perplexity: 22.9831\n",
      "Epoch [1/3], Step [1300/12942], Loss: 2.7772, Perplexity: 16.0733\n",
      "Epoch [1/3], Step [1400/12942], Loss: 2.8000, Perplexity: 16.4451\n",
      "Epoch [1/3], Step [1500/12942], Loss: 2.7295, Perplexity: 15.3257\n",
      "Epoch [1/3], Step [1600/12942], Loss: 2.8449, Perplexity: 17.1995\n",
      "Epoch [1/3], Step [1700/12942], Loss: 2.7560, Perplexity: 15.7362\n",
      "Epoch [1/3], Step [1800/12942], Loss: 2.3745, Perplexity: 10.7457\n",
      "Epoch [1/3], Step [1900/12942], Loss: 3.0446, Perplexity: 21.0023\n",
      "Epoch [1/3], Step [2000/12942], Loss: 2.3895, Perplexity: 10.9086\n",
      "Epoch [1/3], Step [2100/12942], Loss: 2.6516, Perplexity: 14.1769\n",
      "Epoch [1/3], Step [2200/12942], Loss: 2.7988, Perplexity: 16.4241\n",
      "Epoch [1/3], Step [2300/12942], Loss: 2.6966, Perplexity: 14.8291\n",
      "Epoch [1/3], Step [2400/12942], Loss: 2.7686, Perplexity: 15.9359\n",
      "Epoch [1/3], Step [2500/12942], Loss: 2.5177, Perplexity: 12.3997\n",
      "Epoch [1/3], Step [2600/12942], Loss: 2.2742, Perplexity: 9.72011\n",
      "Epoch [1/3], Step [2700/12942], Loss: 2.3873, Perplexity: 10.8840\n",
      "Epoch [1/3], Step [2800/12942], Loss: 2.6971, Perplexity: 14.8362\n",
      "Epoch [1/3], Step [2900/12942], Loss: 2.3642, Perplexity: 10.6357\n",
      "Epoch [1/3], Step [3000/12942], Loss: 2.3446, Perplexity: 10.4294\n",
      "Epoch [1/3], Step [3100/12942], Loss: 2.5543, Perplexity: 12.8622\n",
      "Epoch [1/3], Step [3200/12942], Loss: 2.5595, Perplexity: 12.9289\n",
      "Epoch [1/3], Step [3300/12942], Loss: 2.6052, Perplexity: 13.5333\n",
      "Epoch [1/3], Step [3400/12942], Loss: 3.2697, Perplexity: 26.3032\n",
      "Epoch [1/3], Step [3500/12942], Loss: 2.4588, Perplexity: 11.6904\n",
      "Epoch [1/3], Step [3600/12942], Loss: 2.5712, Perplexity: 13.0817\n",
      "Epoch [1/3], Step [3700/12942], Loss: 2.5803, Perplexity: 13.2015\n",
      "Epoch [1/3], Step [3800/12942], Loss: 2.3493, Perplexity: 10.4780\n",
      "Epoch [1/3], Step [3900/12942], Loss: 2.4112, Perplexity: 11.1476\n",
      "Epoch [1/3], Step [4000/12942], Loss: 2.6292, Perplexity: 13.8622\n",
      "Epoch [1/3], Step [4100/12942], Loss: 2.7290, Perplexity: 15.3170\n",
      "Epoch [1/3], Step [4200/12942], Loss: 2.2739, Perplexity: 9.71770\n",
      "Epoch [1/3], Step [4300/12942], Loss: 2.5484, Perplexity: 12.7866\n",
      "Epoch [1/3], Step [4400/12942], Loss: 2.4279, Perplexity: 11.33467\n",
      "Epoch [1/3], Step [4500/12942], Loss: 2.7008, Perplexity: 14.8924\n",
      "Epoch [1/3], Step [4600/12942], Loss: 2.6298, Perplexity: 13.8704\n",
      "Epoch [1/3], Step [4700/12942], Loss: 2.5581, Perplexity: 12.9107\n",
      "Epoch [1/3], Step [4800/12942], Loss: 2.3601, Perplexity: 10.5920\n",
      "Epoch [1/3], Step [4900/12942], Loss: 2.2599, Perplexity: 9.58189\n",
      "Epoch [1/3], Step [5000/12942], Loss: 2.0438, Perplexity: 7.71961\n",
      "Epoch [1/3], Step [5100/12942], Loss: 2.4992, Perplexity: 12.1723\n",
      "Epoch [1/3], Step [5200/12942], Loss: 2.3138, Perplexity: 10.1126\n",
      "Epoch [1/3], Step [5300/12942], Loss: 2.1755, Perplexity: 8.80646\n",
      "Epoch [1/3], Step [5400/12942], Loss: 2.4382, Perplexity: 11.4525\n",
      "Epoch [1/3], Step [5500/12942], Loss: 2.3617, Perplexity: 10.6091\n",
      "Epoch [1/3], Step [5600/12942], Loss: 2.1130, Perplexity: 8.27335\n",
      "Epoch [1/3], Step [5700/12942], Loss: 2.3766, Perplexity: 10.7687\n",
      "Epoch [1/3], Step [5800/12942], Loss: 2.2107, Perplexity: 9.12254\n",
      "Epoch [1/3], Step [5900/12942], Loss: 2.2811, Perplexity: 9.78730\n",
      "Epoch [1/3], Step [6000/12942], Loss: 1.9768, Perplexity: 7.21978\n",
      "Epoch [1/3], Step [6100/12942], Loss: 2.1808, Perplexity: 8.85310\n",
      "Epoch [1/3], Step [6200/12942], Loss: 2.5009, Perplexity: 12.1937\n",
      "Epoch [1/3], Step [6300/12942], Loss: 2.3265, Perplexity: 10.2416\n",
      "Epoch [1/3], Step [6400/12942], Loss: 2.4266, Perplexity: 11.3199\n",
      "Epoch [1/3], Step [6500/12942], Loss: 2.2412, Perplexity: 9.40504\n",
      "Epoch [1/3], Step [6600/12942], Loss: 2.4137, Perplexity: 11.1747\n",
      "Epoch [1/3], Step [6700/12942], Loss: 2.1727, Perplexity: 8.78181\n",
      "Epoch [1/3], Step [6800/12942], Loss: 2.2715, Perplexity: 9.69373\n",
      "Epoch [1/3], Step [6900/12942], Loss: 2.3404, Perplexity: 10.3859\n",
      "Epoch [1/3], Step [7000/12942], Loss: 2.6505, Perplexity: 14.1612\n",
      "Epoch [1/3], Step [7100/12942], Loss: 2.3210, Perplexity: 10.1863\n",
      "Epoch [1/3], Step [7200/12942], Loss: 2.0790, Perplexity: 7.99630\n",
      "Epoch [1/3], Step [7300/12942], Loss: 2.3483, Perplexity: 10.46751\n",
      "Epoch [1/3], Step [7400/12942], Loss: 2.0941, Perplexity: 8.11813\n",
      "Epoch [1/3], Step [7500/12942], Loss: 2.1680, Perplexity: 8.74127\n",
      "Epoch [1/3], Step [7600/12942], Loss: 2.3925, Perplexity: 10.9412\n",
      "Epoch [1/3], Step [7700/12942], Loss: 2.3979, Perplexity: 11.0005\n",
      "Epoch [1/3], Step [7800/12942], Loss: 2.8421, Perplexity: 17.1517\n",
      "Epoch [1/3], Step [7900/12942], Loss: 2.4100, Perplexity: 11.1336\n",
      "Epoch [1/3], Step [8000/12942], Loss: 2.4852, Perplexity: 12.0039\n",
      "Epoch [1/3], Step [8100/12942], Loss: 2.0248, Perplexity: 7.57485\n",
      "Epoch [1/3], Step [8200/12942], Loss: 2.6703, Perplexity: 14.4447\n",
      "Epoch [1/3], Step [8300/12942], Loss: 2.5325, Perplexity: 12.5846\n",
      "Epoch [1/3], Step [8400/12942], Loss: 2.1666, Perplexity: 8.72818\n",
      "Epoch [1/3], Step [8500/12942], Loss: 2.2898, Perplexity: 9.87337\n",
      "Epoch [1/3], Step [8600/12942], Loss: 2.3211, Perplexity: 10.1871\n",
      "Epoch [1/3], Step [8700/12942], Loss: 2.2357, Perplexity: 9.35292\n",
      "Epoch [1/3], Step [8800/12942], Loss: 2.7596, Perplexity: 15.7936\n",
      "Epoch [1/3], Step [8900/12942], Loss: 2.1379, Perplexity: 8.48142\n",
      "Epoch [1/3], Step [9000/12942], Loss: 2.2763, Perplexity: 9.74087\n",
      "Epoch [1/3], Step [9100/12942], Loss: 2.5072, Perplexity: 12.2710\n",
      "Epoch [1/3], Step [9200/12942], Loss: 2.3117, Perplexity: 10.0917\n",
      "Epoch [1/3], Step [9300/12942], Loss: 2.5167, Perplexity: 12.3882\n",
      "Epoch [1/3], Step [9400/12942], Loss: 2.3615, Perplexity: 10.6064\n",
      "Epoch [1/3], Step [9500/12942], Loss: 2.4407, Perplexity: 11.4811\n",
      "Epoch [1/3], Step [9600/12942], Loss: 2.0061, Perplexity: 7.43428\n",
      "Epoch [1/3], Step [9700/12942], Loss: 2.7398, Perplexity: 15.4840\n",
      "Epoch [1/3], Step [9800/12942], Loss: 1.9943, Perplexity: 7.34680\n",
      "Epoch [1/3], Step [9900/12942], Loss: 2.1835, Perplexity: 8.87761\n",
      "Epoch [1/3], Step [10000/12942], Loss: 2.1166, Perplexity: 8.3030\n",
      "Epoch [1/3], Step [10100/12942], Loss: 2.3269, Perplexity: 10.2462\n",
      "Epoch [1/3], Step [10200/12942], Loss: 2.6017, Perplexity: 13.4869\n",
      "Epoch [1/3], Step [10300/12942], Loss: 2.2970, Perplexity: 9.94458\n",
      "Epoch [1/3], Step [10400/12942], Loss: 2.0819, Perplexity: 8.01993\n",
      "Epoch [1/3], Step [10500/12942], Loss: 2.1033, Perplexity: 8.19346\n",
      "Epoch [1/3], Step [10600/12942], Loss: 2.1609, Perplexity: 8.67903\n",
      "Epoch [1/3], Step [10700/12942], Loss: 2.1775, Perplexity: 8.82395\n",
      "Epoch [1/3], Step [10800/12942], Loss: 1.9658, Perplexity: 7.14044\n",
      "Epoch [1/3], Step [10900/12942], Loss: 2.7042, Perplexity: 14.9423\n",
      "Epoch [1/3], Step [11000/12942], Loss: 2.3177, Perplexity: 10.1526\n",
      "Epoch [1/3], Step [11100/12942], Loss: 2.0746, Perplexity: 7.96150\n",
      "Epoch [1/3], Step [11200/12942], Loss: 2.5131, Perplexity: 12.3426\n",
      "Epoch [1/3], Step [11300/12942], Loss: 2.4076, Perplexity: 11.1077\n",
      "Epoch [1/3], Step [11400/12942], Loss: 2.1962, Perplexity: 8.99077\n",
      "Epoch [1/3], Step [11500/12942], Loss: 2.8044, Perplexity: 16.5165\n",
      "Epoch [1/3], Step [11600/12942], Loss: 2.3111, Perplexity: 10.0858\n",
      "Epoch [1/3], Step [11700/12942], Loss: 2.4961, Perplexity: 12.1356\n",
      "Epoch [1/3], Step [11800/12942], Loss: 2.2882, Perplexity: 9.85706\n",
      "Epoch [1/3], Step [11900/12942], Loss: 2.2621, Perplexity: 9.60378\n",
      "Epoch [1/3], Step [12000/12942], Loss: 2.0089, Perplexity: 7.45497\n",
      "Epoch [1/3], Step [12100/12942], Loss: 2.1854, Perplexity: 8.89461\n",
      "Epoch [1/3], Step [12200/12942], Loss: 2.2212, Perplexity: 9.21802\n",
      "Epoch [1/3], Step [12300/12942], Loss: 2.5624, Perplexity: 12.9666\n",
      "Epoch [1/3], Step [12400/12942], Loss: 2.1672, Perplexity: 8.73426\n",
      "Epoch [1/3], Step [12500/12942], Loss: 2.2410, Perplexity: 9.40288\n",
      "Epoch [1/3], Step [12600/12942], Loss: 2.6528, Perplexity: 14.1939\n",
      "Epoch [1/3], Step [12700/12942], Loss: 2.0940, Perplexity: 8.11774\n",
      "Epoch [1/3], Step [12800/12942], Loss: 2.2067, Perplexity: 9.08597\n",
      "Epoch [1/3], Step [12900/12942], Loss: 2.4004, Perplexity: 11.0279\n",
      "Epoch [2/3], Step [100/12942], Loss: 2.1419, Perplexity: 8.5155983\n",
      "Epoch [2/3], Step [200/12942], Loss: 2.1391, Perplexity: 8.49175\n",
      "Epoch [2/3], Step [300/12942], Loss: 2.3420, Perplexity: 10.4018\n",
      "Epoch [2/3], Step [400/12942], Loss: 2.3060, Perplexity: 10.0344\n",
      "Epoch [2/3], Step [500/12942], Loss: 1.9529, Perplexity: 7.04913\n",
      "Epoch [2/3], Step [600/12942], Loss: 2.3258, Perplexity: 10.2353\n",
      "Epoch [2/3], Step [700/12942], Loss: 2.4531, Perplexity: 11.6238\n",
      "Epoch [2/3], Step [800/12942], Loss: 2.1708, Perplexity: 8.76525\n",
      "Epoch [2/3], Step [900/12942], Loss: 2.1701, Perplexity: 8.75939\n",
      "Epoch [2/3], Step [1000/12942], Loss: 2.5844, Perplexity: 13.2556\n",
      "Epoch [2/3], Step [1100/12942], Loss: 2.0183, Perplexity: 7.52544\n",
      "Epoch [2/3], Step [1200/12942], Loss: 2.5921, Perplexity: 13.3574\n",
      "Epoch [2/3], Step [1300/12942], Loss: 3.3165, Perplexity: 27.5645\n",
      "Epoch [2/3], Step [1400/12942], Loss: 2.1995, Perplexity: 9.02073\n",
      "Epoch [2/3], Step [1500/12942], Loss: 2.3273, Perplexity: 10.2503\n",
      "Epoch [2/3], Step [1600/12942], Loss: 2.0581, Perplexity: 7.83128\n",
      "Epoch [2/3], Step [1700/12942], Loss: 2.2208, Perplexity: 9.21461\n",
      "Epoch [2/3], Step [1800/12942], Loss: 1.9819, Perplexity: 7.25639\n",
      "Epoch [2/3], Step [1900/12942], Loss: 2.1508, Perplexity: 8.59131\n",
      "Epoch [2/3], Step [2000/12942], Loss: 2.0736, Perplexity: 7.95348\n",
      "Epoch [2/3], Step [2100/12942], Loss: 2.0770, Perplexity: 7.98074\n",
      "Epoch [2/3], Step [2200/12942], Loss: 2.1598, Perplexity: 8.66934\n",
      "Epoch [2/3], Step [2300/12942], Loss: 2.3481, Perplexity: 10.4660\n",
      "Epoch [2/3], Step [2400/12942], Loss: 2.1091, Perplexity: 8.24080\n",
      "Epoch [2/3], Step [2500/12942], Loss: 1.8895, Perplexity: 6.61615\n",
      "Epoch [2/3], Step [2600/12942], Loss: 2.1727, Perplexity: 8.78211\n",
      "Epoch [2/3], Step [2700/12942], Loss: 1.9095, Perplexity: 6.74997\n",
      "Epoch [2/3], Step [2800/12942], Loss: 2.4265, Perplexity: 11.3188\n",
      "Epoch [2/3], Step [2900/12942], Loss: 1.9071, Perplexity: 6.73370\n",
      "Epoch [2/3], Step [3000/12942], Loss: 2.1571, Perplexity: 8.64604\n",
      "Epoch [2/3], Step [3100/12942], Loss: 2.3858, Perplexity: 10.8679\n",
      "Epoch [2/3], Step [3200/12942], Loss: 2.1394, Perplexity: 8.49460\n",
      "Epoch [2/3], Step [3300/12942], Loss: 2.2204, Perplexity: 9.21082\n",
      "Epoch [2/3], Step [3400/12942], Loss: 2.0904, Perplexity: 8.08844\n",
      "Epoch [2/3], Step [3500/12942], Loss: 2.2858, Perplexity: 9.83326\n",
      "Epoch [2/3], Step [3600/12942], Loss: 2.1626, Perplexity: 8.69361\n",
      "Epoch [2/3], Step [3700/12942], Loss: 2.0465, Perplexity: 7.74085\n",
      "Epoch [2/3], Step [3800/12942], Loss: 2.1421, Perplexity: 8.51730\n",
      "Epoch [2/3], Step [3900/12942], Loss: 2.1577, Perplexity: 8.65164\n",
      "Epoch [2/3], Step [4000/12942], Loss: 1.9709, Perplexity: 7.17704\n",
      "Epoch [2/3], Step [4100/12942], Loss: 2.2646, Perplexity: 9.62770\n",
      "Epoch [2/3], Step [4200/12942], Loss: 2.4272, Perplexity: 11.3277\n",
      "Epoch [2/3], Step [4300/12942], Loss: 2.0151, Perplexity: 7.50155\n",
      "Epoch [2/3], Step [4400/12942], Loss: 1.9818, Perplexity: 7.25542\n",
      "Epoch [2/3], Step [4500/12942], Loss: 1.9812, Perplexity: 7.25125\n",
      "Epoch [2/3], Step [4600/12942], Loss: 1.9942, Perplexity: 7.34646\n",
      "Epoch [2/3], Step [4700/12942], Loss: 2.3902, Perplexity: 10.9159\n",
      "Epoch [2/3], Step [4800/12942], Loss: 1.7352, Perplexity: 5.66981\n",
      "Epoch [2/3], Step [4900/12942], Loss: 2.2137, Perplexity: 9.14937\n",
      "Epoch [2/3], Step [5000/12942], Loss: 2.1589, Perplexity: 8.661927\n",
      "Epoch [2/3], Step [5100/12942], Loss: 2.0641, Perplexity: 7.87803\n",
      "Epoch [2/3], Step [5200/12942], Loss: 1.7242, Perplexity: 5.60791\n",
      "Epoch [2/3], Step [5300/12942], Loss: 1.9908, Perplexity: 7.32156\n",
      "Epoch [2/3], Step [5400/12942], Loss: 2.2200, Perplexity: 9.20767\n",
      "Epoch [2/3], Step [5500/12942], Loss: 2.0089, Perplexity: 7.45526\n",
      "Epoch [2/3], Step [5600/12942], Loss: 1.9475, Perplexity: 7.01147\n",
      "Epoch [2/3], Step [5700/12942], Loss: 2.2400, Perplexity: 9.39291\n",
      "Epoch [2/3], Step [5800/12942], Loss: 2.0973, Perplexity: 8.14410\n",
      "Epoch [2/3], Step [5900/12942], Loss: 2.2065, Perplexity: 9.08383\n",
      "Epoch [2/3], Step [6000/12942], Loss: 1.9941, Perplexity: 7.34544\n",
      "Epoch [2/3], Step [6100/12942], Loss: 2.5895, Perplexity: 13.3226\n",
      "Epoch [2/3], Step [6200/12942], Loss: 1.7988, Perplexity: 6.04232\n",
      "Epoch [2/3], Step [6300/12942], Loss: 2.3033, Perplexity: 10.0069\n",
      "Epoch [2/3], Step [6400/12942], Loss: 1.9298, Perplexity: 6.88813\n",
      "Epoch [2/3], Step [6500/12942], Loss: 1.9631, Perplexity: 7.121584\n",
      "Epoch [2/3], Step [6600/12942], Loss: 2.3289, Perplexity: 10.2667\n",
      "Epoch [2/3], Step [6700/12942], Loss: 2.2779, Perplexity: 9.75623\n",
      "Epoch [2/3], Step [6800/12942], Loss: 1.8928, Perplexity: 6.63780\n",
      "Epoch [2/3], Step [6900/12942], Loss: 1.9432, Perplexity: 6.98131\n",
      "Epoch [2/3], Step [7000/12942], Loss: 2.2310, Perplexity: 9.30953\n",
      "Epoch [2/3], Step [7100/12942], Loss: 2.2393, Perplexity: 9.38687\n",
      "Epoch [2/3], Step [7200/12942], Loss: 2.1008, Perplexity: 8.17305\n",
      "Epoch [2/3], Step [7300/12942], Loss: 2.1499, Perplexity: 8.58402\n",
      "Epoch [2/3], Step [7400/12942], Loss: 2.4427, Perplexity: 11.5035\n",
      "Epoch [2/3], Step [7500/12942], Loss: 2.1289, Perplexity: 8.40570\n",
      "Epoch [2/3], Step [7600/12942], Loss: 2.1290, Perplexity: 8.40649\n",
      "Epoch [2/3], Step [7700/12942], Loss: 2.5716, Perplexity: 13.0865\n",
      "Epoch [2/3], Step [7800/12942], Loss: 2.1423, Perplexity: 8.51931\n",
      "Epoch [2/3], Step [7900/12942], Loss: 2.2797, Perplexity: 9.77401\n",
      "Epoch [2/3], Step [8000/12942], Loss: 2.1068, Perplexity: 8.22220\n",
      "Epoch [2/3], Step [8100/12942], Loss: 2.2434, Perplexity: 9.42535\n",
      "Epoch [2/3], Step [8200/12942], Loss: 2.2913, Perplexity: 9.88823\n",
      "Epoch [2/3], Step [8300/12942], Loss: 2.1529, Perplexity: 8.61023\n",
      "Epoch [2/3], Step [8400/12942], Loss: 2.3666, Perplexity: 10.6610\n",
      "Epoch [2/3], Step [8500/12942], Loss: 2.0968, Perplexity: 8.14023\n",
      "Epoch [2/3], Step [8600/12942], Loss: 2.0942, Perplexity: 8.11918\n",
      "Epoch [2/3], Step [8700/12942], Loss: 2.1332, Perplexity: 8.44193\n",
      "Epoch [2/3], Step [8800/12942], Loss: 2.2665, Perplexity: 9.64598\n",
      "Epoch [2/3], Step [8900/12942], Loss: 1.9110, Perplexity: 6.76019\n",
      "Epoch [2/3], Step [9000/12942], Loss: 2.0715, Perplexity: 7.93718\n",
      "Epoch [2/3], Step [9100/12942], Loss: 2.1166, Perplexity: 8.30265\n",
      "Epoch [2/3], Step [9200/12942], Loss: 2.0114, Perplexity: 7.47406\n",
      "Epoch [2/3], Step [9300/12942], Loss: 2.1033, Perplexity: 8.19285\n",
      "Epoch [2/3], Step [9400/12942], Loss: 1.9801, Perplexity: 7.24372\n",
      "Epoch [2/3], Step [9500/12942], Loss: 2.1049, Perplexity: 8.20663\n",
      "Epoch [2/3], Step [9600/12942], Loss: 2.4192, Perplexity: 11.2373\n",
      "Epoch [2/3], Step [9700/12942], Loss: 3.3582, Perplexity: 28.7365\n",
      "Epoch [2/3], Step [9800/12942], Loss: 2.2199, Perplexity: 9.20645\n",
      "Epoch [2/3], Step [9900/12942], Loss: 2.1097, Perplexity: 8.24594\n",
      "Epoch [2/3], Step [10000/12942], Loss: 2.1644, Perplexity: 8.7097\n",
      "Epoch [2/3], Step [10100/12942], Loss: 2.1527, Perplexity: 8.60801\n",
      "Epoch [2/3], Step [10200/12942], Loss: 2.1720, Perplexity: 8.77623\n",
      "Epoch [2/3], Step [10300/12942], Loss: 2.1457, Perplexity: 8.54809\n",
      "Epoch [2/3], Step [10400/12942], Loss: 1.7895, Perplexity: 5.98654\n",
      "Epoch [2/3], Step [10500/12942], Loss: 2.0217, Perplexity: 7.55093\n",
      "Epoch [2/3], Step [10600/12942], Loss: 1.7989, Perplexity: 6.04280\n",
      "Epoch [2/3], Step [10700/12942], Loss: 2.1902, Perplexity: 8.93677\n",
      "Epoch [2/3], Step [10800/12942], Loss: 2.2118, Perplexity: 9.13174\n",
      "Epoch [2/3], Step [10900/12942], Loss: 2.0996, Perplexity: 8.16323\n",
      "Epoch [2/3], Step [11000/12942], Loss: 2.3695, Perplexity: 10.6920\n",
      "Epoch [2/3], Step [11100/12942], Loss: 1.9986, Perplexity: 7.37902\n",
      "Epoch [2/3], Step [11200/12942], Loss: 1.7572, Perplexity: 5.79625\n",
      "Epoch [2/3], Step [11300/12942], Loss: 2.1353, Perplexity: 8.45985\n",
      "Epoch [2/3], Step [11400/12942], Loss: 2.6981, Perplexity: 14.8509\n",
      "Epoch [2/3], Step [11500/12942], Loss: 1.9624, Perplexity: 7.116781\n",
      "Epoch [2/3], Step [11600/12942], Loss: 2.0605, Perplexity: 7.85002\n",
      "Epoch [2/3], Step [11700/12942], Loss: 2.1656, Perplexity: 8.72031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Step [11800/12942], Loss: 1.9656, Perplexity: 7.13944\n",
      "Epoch [2/3], Step [11900/12942], Loss: 1.9877, Perplexity: 7.29871\n",
      "Epoch [2/3], Step [12000/12942], Loss: 2.8802, Perplexity: 17.8178\n",
      "Epoch [2/3], Step [12100/12942], Loss: 1.9682, Perplexity: 7.15757\n",
      "Epoch [2/3], Step [12200/12942], Loss: 2.0908, Perplexity: 8.09119\n",
      "Epoch [2/3], Step [12300/12942], Loss: 2.7022, Perplexity: 14.9123\n",
      "Epoch [2/3], Step [12400/12942], Loss: 1.9619, Perplexity: 7.11272\n",
      "Epoch [2/3], Step [12500/12942], Loss: 1.8641, Perplexity: 6.45013\n",
      "Epoch [2/3], Step [12600/12942], Loss: 1.9902, Perplexity: 7.31715\n",
      "Epoch [2/3], Step [12700/12942], Loss: 1.9386, Perplexity: 6.94870\n",
      "Epoch [2/3], Step [12800/12942], Loss: 2.0791, Perplexity: 7.99766\n",
      "Epoch [2/3], Step [12900/12942], Loss: 1.8186, Perplexity: 6.16319\n",
      "Epoch [3/3], Step [100/12942], Loss: 2.0122, Perplexity: 7.4794226\n",
      "Epoch [3/3], Step [200/12942], Loss: 1.8638, Perplexity: 6.44849\n",
      "Epoch [3/3], Step [300/12942], Loss: 2.0123, Perplexity: 7.48070\n",
      "Epoch [3/3], Step [400/12942], Loss: 2.1698, Perplexity: 8.75619\n",
      "Epoch [3/3], Step [500/12942], Loss: 1.9768, Perplexity: 7.21956\n",
      "Epoch [3/3], Step [600/12942], Loss: 2.0900, Perplexity: 8.08497\n",
      "Epoch [3/3], Step [700/12942], Loss: 2.0934, Perplexity: 8.11238\n",
      "Epoch [3/3], Step [800/12942], Loss: 1.9771, Perplexity: 7.22187\n",
      "Epoch [3/3], Step [900/12942], Loss: 2.3356, Perplexity: 10.3352\n",
      "Epoch [3/3], Step [1000/12942], Loss: 2.0798, Perplexity: 8.0033\n",
      "Epoch [3/3], Step [1100/12942], Loss: 1.9826, Perplexity: 7.26173\n",
      "Epoch [3/3], Step [1200/12942], Loss: 1.8885, Perplexity: 6.60968\n",
      "Epoch [3/3], Step [1300/12942], Loss: 2.0776, Perplexity: 7.98526\n",
      "Epoch [3/3], Step [1400/12942], Loss: 1.9743, Perplexity: 7.20175\n",
      "Epoch [3/3], Step [1500/12942], Loss: 2.1277, Perplexity: 8.39527\n",
      "Epoch [3/3], Step [1600/12942], Loss: 2.2531, Perplexity: 9.51742\n",
      "Epoch [3/3], Step [1700/12942], Loss: 1.8878, Perplexity: 6.60502\n",
      "Epoch [3/3], Step [1800/12942], Loss: 2.6225, Perplexity: 13.7704\n",
      "Epoch [3/3], Step [1900/12942], Loss: 2.1156, Perplexity: 8.29424\n",
      "Epoch [3/3], Step [2000/12942], Loss: 3.7752, Perplexity: 43.6064\n",
      "Epoch [3/3], Step [2100/12942], Loss: 1.9255, Perplexity: 6.85879\n",
      "Epoch [3/3], Step [2200/12942], Loss: 1.8717, Perplexity: 6.49939\n",
      "Epoch [3/3], Step [2300/12942], Loss: 1.8964, Perplexity: 6.66165\n",
      "Epoch [3/3], Step [2400/12942], Loss: 1.7814, Perplexity: 5.93811\n",
      "Epoch [3/3], Step [2500/12942], Loss: 2.0381, Perplexity: 7.67588\n",
      "Epoch [3/3], Step [2600/12942], Loss: 2.0497, Perplexity: 7.76586\n",
      "Epoch [3/3], Step [2700/12942], Loss: 1.7272, Perplexity: 5.62466\n",
      "Epoch [3/3], Step [2800/12942], Loss: 2.4694, Perplexity: 11.8150\n",
      "Epoch [3/3], Step [2900/12942], Loss: 1.7905, Perplexity: 5.99233\n",
      "Epoch [3/3], Step [3000/12942], Loss: 1.9439, Perplexity: 6.98589\n",
      "Epoch [3/3], Step [3100/12942], Loss: 2.0323, Perplexity: 7.63151\n",
      "Epoch [3/3], Step [3200/12942], Loss: 2.0142, Perplexity: 7.49466\n",
      "Epoch [3/3], Step [3300/12942], Loss: 2.1154, Perplexity: 8.29292\n",
      "Epoch [3/3], Step [3400/12942], Loss: 2.0171, Perplexity: 7.51632\n",
      "Epoch [3/3], Step [3500/12942], Loss: 1.9152, Perplexity: 6.78823\n",
      "Epoch [3/3], Step [3600/12942], Loss: 1.9053, Perplexity: 6.72129\n",
      "Epoch [3/3], Step [3700/12942], Loss: 2.2267, Perplexity: 9.26882\n",
      "Epoch [3/3], Step [3800/12942], Loss: 1.9762, Perplexity: 7.21537\n",
      "Epoch [3/3], Step [3900/12942], Loss: 2.1603, Perplexity: 8.67390\n",
      "Epoch [3/3], Step [4000/12942], Loss: 2.3380, Perplexity: 10.3606\n",
      "Epoch [3/3], Step [4100/12942], Loss: 1.9439, Perplexity: 6.98639\n",
      "Epoch [3/3], Step [4200/12942], Loss: 2.2307, Perplexity: 9.30675\n",
      "Epoch [3/3], Step [4300/12942], Loss: 2.2392, Perplexity: 9.38591\n",
      "Epoch [3/3], Step [4400/12942], Loss: 1.9702, Perplexity: 7.17183\n",
      "Epoch [3/3], Step [4500/12942], Loss: 2.3878, Perplexity: 10.8899\n",
      "Epoch [3/3], Step [4600/12942], Loss: 2.1467, Perplexity: 8.55661\n",
      "Epoch [3/3], Step [4700/12942], Loss: 1.8247, Perplexity: 6.20071\n",
      "Epoch [3/3], Step [4800/12942], Loss: 2.0187, Perplexity: 7.52887\n",
      "Epoch [3/3], Step [4900/12942], Loss: 2.0959, Perplexity: 8.13286\n",
      "Epoch [3/3], Step [5000/12942], Loss: 2.0006, Perplexity: 7.39317\n",
      "Epoch [3/3], Step [5100/12942], Loss: 2.0897, Perplexity: 8.08228\n",
      "Epoch [3/3], Step [5200/12942], Loss: 2.0828, Perplexity: 8.02734\n",
      "Epoch [3/3], Step [5300/12942], Loss: 2.0175, Perplexity: 7.51942\n",
      "Epoch [3/3], Step [5400/12942], Loss: 2.0357, Perplexity: 7.65798\n",
      "Epoch [3/3], Step [5500/12942], Loss: 1.9602, Perplexity: 7.10079\n",
      "Epoch [3/3], Step [5600/12942], Loss: 2.1626, Perplexity: 8.69386\n",
      "Epoch [3/3], Step [5700/12942], Loss: 2.0411, Perplexity: 7.69942\n",
      "Epoch [3/3], Step [5800/12942], Loss: 1.8856, Perplexity: 6.59020\n",
      "Epoch [3/3], Step [5900/12942], Loss: 2.3280, Perplexity: 10.2573\n",
      "Epoch [3/3], Step [6000/12942], Loss: 2.3625, Perplexity: 10.6179\n",
      "Epoch [3/3], Step [6100/12942], Loss: 2.2211, Perplexity: 9.21733\n",
      "Epoch [3/3], Step [6200/12942], Loss: 2.2340, Perplexity: 9.33713\n",
      "Epoch [3/3], Step [6300/12942], Loss: 2.0705, Perplexity: 7.92869\n",
      "Epoch [3/3], Step [6400/12942], Loss: 1.8580, Perplexity: 6.41115\n",
      "Epoch [3/3], Step [6500/12942], Loss: 2.0317, Perplexity: 7.62672\n",
      "Epoch [3/3], Step [6600/12942], Loss: 2.0292, Perplexity: 7.60806\n",
      "Epoch [3/3], Step [6700/12942], Loss: 2.1530, Perplexity: 8.61087\n",
      "Epoch [3/3], Step [6800/12942], Loss: 2.2674, Perplexity: 9.65456\n",
      "Epoch [3/3], Step [6900/12942], Loss: 2.1340, Perplexity: 8.44878\n",
      "Epoch [3/3], Step [7000/12942], Loss: 3.7113, Perplexity: 40.9049\n",
      "Epoch [3/3], Step [7100/12942], Loss: 1.9560, Perplexity: 7.070985\n",
      "Epoch [3/3], Step [7200/12942], Loss: 1.8672, Perplexity: 6.47015\n",
      "Epoch [3/3], Step [7300/12942], Loss: 1.9204, Perplexity: 6.82386\n",
      "Epoch [3/3], Step [7400/12942], Loss: 2.2098, Perplexity: 9.11378\n",
      "Epoch [3/3], Step [7500/12942], Loss: 2.4774, Perplexity: 11.9104\n",
      "Epoch [3/3], Step [7600/12942], Loss: 1.8681, Perplexity: 6.47587\n",
      "Epoch [3/3], Step [7700/12942], Loss: 2.2238, Perplexity: 9.24278\n",
      "Epoch [3/3], Step [7800/12942], Loss: 2.0637, Perplexity: 7.87541\n",
      "Epoch [3/3], Step [7900/12942], Loss: 1.9493, Perplexity: 7.02405\n",
      "Epoch [3/3], Step [8000/12942], Loss: 2.2908, Perplexity: 9.88295\n",
      "Epoch [3/3], Step [8100/12942], Loss: 2.0874, Perplexity: 8.06402\n",
      "Epoch [3/3], Step [8200/12942], Loss: 1.9873, Perplexity: 7.29595\n",
      "Epoch [3/3], Step [8300/12942], Loss: 2.2490, Perplexity: 9.47848\n",
      "Epoch [3/3], Step [8400/12942], Loss: 1.9168, Perplexity: 6.79916\n",
      "Epoch [3/3], Step [8500/12942], Loss: 2.1809, Perplexity: 8.85447\n",
      "Epoch [3/3], Step [8600/12942], Loss: 1.7818, Perplexity: 5.94077\n",
      "Epoch [3/3], Step [8700/12942], Loss: 2.0828, Perplexity: 8.02708\n",
      "Epoch [3/3], Step [8800/12942], Loss: 2.5484, Perplexity: 12.7862\n",
      "Epoch [3/3], Step [8900/12942], Loss: 2.2165, Perplexity: 9.17497\n",
      "Epoch [3/3], Step [9000/12942], Loss: 1.7107, Perplexity: 5.53298\n",
      "Epoch [3/3], Step [9100/12942], Loss: 2.0511, Perplexity: 7.77670\n",
      "Epoch [3/3], Step [9200/12942], Loss: 2.0739, Perplexity: 7.95548\n",
      "Epoch [3/3], Step [9300/12942], Loss: 1.7830, Perplexity: 5.94779\n",
      "Epoch [3/3], Step [9400/12942], Loss: 2.0859, Perplexity: 8.05218\n",
      "Epoch [3/3], Step [9500/12942], Loss: 1.9729, Perplexity: 7.19184\n",
      "Epoch [3/3], Step [9600/12942], Loss: 1.9826, Perplexity: 7.26146\n",
      "Epoch [3/3], Step [9700/12942], Loss: 2.1515, Perplexity: 8.59769\n",
      "Epoch [3/3], Step [9800/12942], Loss: 2.0023, Perplexity: 7.40649\n",
      "Epoch [3/3], Step [9900/12942], Loss: 1.9446, Perplexity: 6.99063\n",
      "Epoch [3/3], Step [10000/12942], Loss: 2.3796, Perplexity: 10.8007\n",
      "Epoch [3/3], Step [10100/12942], Loss: 1.8665, Perplexity: 6.46564\n",
      "Epoch [3/3], Step [10200/12942], Loss: 1.8969, Perplexity: 6.66533\n",
      "Epoch [3/3], Step [10300/12942], Loss: 2.4434, Perplexity: 11.5116\n",
      "Epoch [3/3], Step [10400/12942], Loss: 1.8935, Perplexity: 6.64250\n",
      "Epoch [3/3], Step [10500/12942], Loss: 2.2400, Perplexity: 9.39315\n",
      "Epoch [3/3], Step [10600/12942], Loss: 2.3516, Perplexity: 10.5019\n",
      "Epoch [3/3], Step [10700/12942], Loss: 2.2924, Perplexity: 9.89828\n",
      "Epoch [3/3], Step [10800/12942], Loss: 1.8936, Perplexity: 6.64340\n",
      "Epoch [3/3], Step [10900/12942], Loss: 2.2649, Perplexity: 9.63058\n",
      "Epoch [3/3], Step [11000/12942], Loss: 2.0980, Perplexity: 8.14968\n",
      "Epoch [3/3], Step [11100/12942], Loss: 1.9813, Perplexity: 7.25209\n",
      "Epoch [3/3], Step [11200/12942], Loss: 2.0563, Perplexity: 7.81692\n",
      "Epoch [3/3], Step [11300/12942], Loss: 1.9005, Perplexity: 6.68912\n",
      "Epoch [3/3], Step [11400/12942], Loss: 1.8027, Perplexity: 6.06607\n",
      "Epoch [3/3], Step [11500/12942], Loss: 2.1589, Perplexity: 8.66125\n",
      "Epoch [3/3], Step [11600/12942], Loss: 2.0784, Perplexity: 7.99203\n",
      "Epoch [3/3], Step [11700/12942], Loss: 2.0857, Perplexity: 8.05013\n",
      "Epoch [3/3], Step [11800/12942], Loss: 1.9540, Perplexity: 7.05683\n",
      "Epoch [3/3], Step [11900/12942], Loss: 2.2161, Perplexity: 9.17191\n",
      "Epoch [3/3], Step [12000/12942], Loss: 2.1756, Perplexity: 8.80731\n",
      "Epoch [3/3], Step [12100/12942], Loss: 2.0187, Perplexity: 7.52894\n",
      "Epoch [3/3], Step [12200/12942], Loss: 1.8114, Perplexity: 6.11937\n",
      "Epoch [3/3], Step [12300/12942], Loss: 2.0901, Perplexity: 8.08591\n",
      "Epoch [3/3], Step [12400/12942], Loss: 1.9123, Perplexity: 6.76867\n",
      "Epoch [3/3], Step [12500/12942], Loss: 1.8510, Perplexity: 6.36604\n",
      "Epoch [3/3], Step [12600/12942], Loss: 2.2018, Perplexity: 9.04123\n",
      "Epoch [3/3], Step [12700/12942], Loss: 2.0694, Perplexity: 7.92035\n",
      "Epoch [3/3], Step [12800/12942], Loss: 1.9038, Perplexity: 6.71146\n",
      "Epoch [3/3], Step [12900/12942], Loss: 1.8689, Perplexity: 6.48120\n",
      "Epoch [3/3], Step [12942/12942], Loss: 1.9807, Perplexity: 7.24815"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
